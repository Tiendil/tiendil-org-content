---
title = "Notes on AI in 2024: Generative Knowledge Base"
tags = ["theory", "neural-networks", "ai-notes-2024", "interesting"]
series = "ai-notes-2024"
published_at = "2024-11-13T17:00:00+00:00"
seo_description = "My notes on the current state of AI at the end of 2024, this part is about the basic AI technology — the generative knowledge base."
seo_image = ""
---

I continue my notes on AI at the end of 2024.

/// brigid-series
id = "ai-notes-2024"
///

Today I want to talk about the disruptive technology that underlies all modern AI achievements. Or about the concept, or the meta-technology — whichever you prefer.

You’ve probably never come across the logic described below on the internet (except for the introduction about disruptive technologies) — engineers and mathematicians might get a bit annoyed by the oversimplifications and cutting corners. But this is the lens through which I view the industry, assess what’s possible and less likely, and so on. My blog, my rules, my dictionary :-D

So, keep in mind — this is my personal view, not a generally accepted one.

<!-- more -->

## Подрывные технологии

Этот термин довольно известен, например, про него есть [статья на википедии](https://ru.wikipedia.org/wiki/Подрывные_инновации). Во многом про них же пишет [Тима О’Рейли](https://ru.wikipedia.org/wiki/О’Райли,_Тим) в книге [WTF?}{post:about-book-wtf}, обзор которой я уже делал.

Поэтому много расписывать про эту концепцию не буду.

Утрируя, подрывная технология меняет правила игры на рынке, а не даёт преимущества в рамках установившихся правил. Соответственно, появление подрывной технологии создаёт новые рынки и убивает старые. Хорошим примером подрывной технологии будет цифровая фотография, «убившая» Kodak и плёночный масс-маркет.

Выделять технологии, благодаря которым ИИ «подрывает» всё вокруг можно по-разному.

Например, можно сказать, что их несколько: эмбединги (на самом деле были давно), глубокое обучение нейронок (тоже было давно), сами нейронки (были уже в 50-ых), выделение 100500 миллионов $ на кластера (так себе технлология), новые архитектуры нейронок (выберите свою любимую), LLM чаты, etc.

Или, можно сказать, что ИИ и есть подрывная технология. Но это слишком абстраткно — никто не может сказать, что такое ИИ, что конкретно оно может и как конкретно его можно применять.

Я, следуя мнению Тима О’Рейли, считаю, что подрывные технологии не атомарны. Наоборот, подрывная технология появляется как удачная комбинация нескольких уже известных атомарных технологий и концепций, которые совместно демонстрируют сильные эмерджентные свойства. Со временем эти свойства выделяются в отдельную концепцию, которая может менять технологии под собой.

Например, не так важно как именно делаются цифровые фотографии, как важны лёгкость их редактирования и передачи. Или не так важно каким образом определяется положение водителей в Uber, как возможность управлять заказами для них на основе локации.

Когда появляется подрывная подобная технология, она не сразу становится заметна. Можно сказать, человечество не сразу её осознаёт как целостную концепцию. На мой взгляд осознание происходит постфактум и все говорят «да, это же очевидно, я всегда это говорил».

Для инженеров первые версии технологии будут просто интересным сочетанием боянных штук. Инженеры либо пропустят цельную картину либо выделяет какой-нибудь частный случай. Как пример такого частного случая я бы привёл [Large Language Models](https://en.wikipedia.org/wiki/Large_language_model) — пары лет не прошло как потребовалось расширять концепцию на мультимодальность.

Для бизнеса, и маркетологов в частности, важнее воспользоваться преимуществом и продать побыстрее, чем разбираться на чём основан их продукт. Примером такого подхода я бы назвал термин «Исуственный Интеллект», из которого за последние 50 лет стабильно вылазят разного уровня технологии, как только становятся достаточно взрослыми, чтобы видеть их границы: экспертные системы, распознавание изображений, логическое программирование, etc.

Хочешь чтобы было сделано хорошо — сделай это сам, поэтому я взял на себя смелость придумать хороший термин под новую технологию.

## Generative Knowledge Base

На мой взгляд, подрывная технология — это новый тип баз данных, основаный на статистике и хранящий семантику вместо реальных целостных данных.

Я пообщался с ChatGPT, чтобы придумать крутое название для этой технологии и сеть предложила `Generative Knowledge Base` — `GKB`. На мой взгляд суть ухвачена довольно чётко, поэтому далее для краткости буду использовать эту аббревиатуру.

`GKB` обладает следующими свойствами:

- Хранение информации с потерями.
- Автоматическое выявление и хранение семантических связей между частями информации.
- **Извлечение информации как вероятностного дополнения запроса**. Не обязательно самого вероятного, но обычно «достаточно вероятного». В случае чатов это однозначно заметно, в случае каких-нибудь графических трансфоормеров и прочих штук — нужно немного копнуть, но суть остаётся та же: мы фомируем некоторое утверждение и получаем его вероятностное дополнение через призму свойств нейронки. В случае чатов дополнением — это буквальное продолжение диалога. В случае, например, переноса стиля изображения — это дополнение.
- **Возможность корректировки вероятности формы ответа**. Самый простой пример — чаты. Дообучая `LLM` на примерах диалогов, мы получаем базу данных, которая отвечает продолжением диалога, но ничто не мешает добучить ту же LLM продолжать монолог, дополнять запрос его переводом на другой язык и так далее.

## Важно разделять свойства `GKB` и свойства её конкретных реализаций

Для примера давайте посмотрим на технологию классических реляционных баз данных. Они написаны  на разных языках, дают разные гарантии атомарности, сохранности данных, конкурентности, по-разному соотносятся с [CAP-теоремой](https://ru.wikipedia.org/wiki/Теорема_CAP), имеют разные профили производительности и так далее. Но концептуально обладают общими базовыми свойствами — [реляционной алгеброй](https://ru.wikipedia.org/wiki/Реляционная_алгебра). Именно на реляционной алгебре, а не на особенностях её реализации, сейчас и стоит большая часть нашего IT мира.

Атомарные технологии под `GKB` сейчас вполне конкретные (большие данные, нейронки, специализированные видеокарты), но концептуально технология могла бы быть построена и на других составляющих. Например, на голосовании 100500 человек, или на [генетическом программировании](https://ru.wikipedia.org/wiki/Генетическое_программирование) поверх квантовых компьютеров. Просто так эволюционно сложилось, что в нашем конкретном случае эту базу собрали на нейронках. Эти альтернативные реализации имели бы другие наборы второстепенных преимуществ и недостатков, но для их успеха потребовался бы тот же набор базовых свойств.

Поэтому я постарался разделить базовые свойства `GKB` (описны выше) и свойства специфичные для текущих реализаций. Вот некоторые из последних.

**Текстовые интерфейсы** (LLM). Наблюдая за текущими трендами, можно подумать что LLM победили и скоро всё будет большими языковыми моделями с мультимодальностью. Я так не считаю. `GKB` концептуально не ограничены текстом — запросы можно строить на любой информации. Просто текстовый интерфейс самый удобный для нашей цивилизации (на текущий момент), так как мы цивилизация текстов. Если вдруг у нас появятся массовые мозговые импланты, может оказаться, что более удобный интерфейс — образный. А если бы эту технологию придумали какие-нибудь глубоководные светящиеся кальмары, то у них основным режимом общения мог бы быть визуальный.

**Сжатие информации в векторную форму** (эмбеддинги). На мой взгляд это типичная особенность реализации. Беспорно удобная и полезна, но нет гарантии, что эмбединги останутся в явном виде — может появиться альтернативное железо на каких-нибудть полях или квантовой запутанности в котором нельзя будет снять данные с промежуточных слоёв без разрушения целостности базы.

**Добавление/модификация информации через обучение с [градиентным спуском](https://ru.wikipedia.org/wiki/Градиентный_спуск)** — также артефакт текущей реализации. Альтернативой мог бы стать, например, какой-нибудь эволюционный отбор. Правда я не возьмусь утверждать, что у нас есть реальная альтернатива (хотя эволюционный отбор мне симпатичнее на порядок). Возможно, градиентный спуск — это действительно самый математически оптимальый способ оптимизации моделей.

## Смотрим на движуху через призму `GKB`

Если вы приглядитесь ко всем прикладным продуктом, за которыми стоит современный ИИ, то увидите, что какие-бы сети они не использовали, концепция взаимодействия продукта с ними одна и та же:

- У нас есть база знаний человечества в какой-то области какого-то качества.
- Мы можем отправить что-то в неё и получить вероятностное дополнение запроса.
- Дополнение может быть неправильным, поэтому мы его проверяем, дублируем, ранжируем ответы и занимаемся всеми возможными штуками, которые позволяют обходить проблемы статистики.
- Всё это сверху и снизу обёрнуто классическими программными компонентами, которые конвертируют данные в/из `GKB`, проверяют их, применяют к чему-то и так далее.

На текущий момент я не слышал о каком-либо концептуально другом подходе к использованию нейронок. Даже на детекцию объектов (нейронками) можно смотреть как на генерацию статистического дополнения к картинке.

Соответственно:

- Если кто-то работает над улучшением базовых свойств `GKB` — к этому следует присмотреться — есть перспектива и вероятность успеха.
- Если кто-то работает над добавлением в нейронки свойств не специфичных для `GKB` — либо это rocket science, либо провальное мероприятие. Подобный rocket science в большинстве случаев тоже закончится провалом.
- Если кто-то пытается использовать нейронки как `GKB` — скорее всего люди понимают что делают и у них есть шанс на успех.
- Если кто-то пытается использовать нейронки не как `GKB`, например создать сильный ИИ или «автономного работника» **только на нейронках, без обвеса** (например, масштабируя нейронку и данные) — скорее всего люди не понимают что делают и у них ничего не получится.

На всякий случай отмечу, что copilot и прочие ассистенты подпадают под третий пункт, а не под четвёртый. Так как типичная функция ассистента — извелечение информации, которую вы потом анализируете. Copilot — не автономный работник, а инструмент для программиста. Это причина, почему некоторые люди не могут извлечь пользы от асистентов — они пытаются взаимодействовать с ними как с людьми, а не как с вероятностной базой знаний.

## `GKB` и сильный искусственный интеллект

Если кратко, то человек — далеко не только база знаний, но и набор логики поверх неё.

Соответственно, рассчитывать на то, что какая-нибудь GPT-10 обретёт сознание не стоит. Во всяком случае, для этого потребуется сильная архитектурная надстройка над GPT и я бы в таком случае использовал новое название :-D

`Generative Knowledge Base` может быть важным куском/модулем для создания сильного ИИ, но всего лишь одним из множества.

Часть из этого множества у нас может быть уже под рукой: разного рода математика и логика, исчисление предикатов, логическое/символьное/функциональное/императивное программирование, традиционные базы данных, семантические сети, тысячи написанных утилит, etc.

Но мы пока не знаем каких ещё модулей не хватает и, тем более, как их объединить в целое. Поэтому до сильного ИИ ещё может пройти довольно много времени.

А вот до его «маркетинговых симуляций» может быть не так далеко.

Возможно одну из будущих заметок я посвящу сильному ИИ и его не очень сильным аналогам.
