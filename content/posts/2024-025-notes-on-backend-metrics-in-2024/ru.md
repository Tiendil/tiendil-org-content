---
title = "Заметки о метриках бэкенд в 2024"
tags = ["practice", "development", "backend", "feeds-fun"]
published_at = "2024-10-27T12:00:00+00:00"
seo_description = "Некоторые заметки о сборе метри на бэке в 2024 году."
seo_image = "./feeds-fun-metrics-schema.png"
---

/// brigid-images
src = "./feeds-fun-metrics-schema.png"
alt = "Примерно так сейчас выглядит сборка метрки в Feeds Fun. Loki (или что-нибудь похожее) пока не развёрнут, но ожидается в будущем."
///

Раз в 2-3 года у меня начинается какой-нибудь новый проект и мне приходится заново разбираться с метриками — как на этот раз их собирать и рисовать. Не то чтобы это единственное, с чем приходится разбираться заново, обычно меняется много всего, но подход к метрикам меняется гарантировано.

Я [слал метрики по UDP]{post:collect-metrics-in-linux} в [Graphite](https://graphiteapp.org/) (в 2024, пост из 2015 выглядит забавно), использовал SaaS-решения вроде [Datadog](https://www.datadoghq.com/) и [New Relic](https://newrelic.com/), аггрегировал метрики в приложении, чтобы их забирал [Prometheus](https://prometheus.io/) и писал метрики в логи для [AWS CloudWatch](https://aws.amazon.com/cloudwatch/).

И всегда были какие-то нюансы.

В метриках пересекается огромное количество областей и интересов:

- Специализированные базы данных для хранения time series.
- Корректность vs достаточность точности vs стоимость поддержки выбранного решения.
- Особенности платформы, на которой разрабатывается проект и его архитектура.
- Идеалогия и личные предпочтения разработчиков.

Поэтому нет одного идеального способа собирать метрики. Более того, разнообразие подходов вкупе с быстрой эволюцией всей области бэкенда привело к появлению огромого количества open-source кирпичей из которых можно собрать любого франкенштейна.

В итоге, когда дошли руки для реализации метрик в [Feeds Fun](https://feeds.fun/) я в очередной раз потратил несколько дней на актуализацию знаний и наведение порядка в голове.

В этом посте я поделюсь некоторыми своими мыслями и решением, которое выбрал для себя. Но не в форме тутуриала, а в форме тезисов с комментариями на темы к которым неравнодушен именно я.

Поскольку я, с большего, бэкендщик, то и рассказывать буду с позиции бэкенда.

<!-- more -->

## Метрики — базовый инструмент для управления технически состоянием проекта на оперативном, тактическом и стратегическом уровнях

Метрики — это буквально глаза разработчика. Без них невозможно видеть как актуальную техническую ситуацию на проекте так и её долгосрочные тренды.

Если брать классический цикл из системной инженерии (и других [мемплексов]{genes-memes-memeplexes}): сбор данных, анализ, синтез (принятие решения), реализация решения, то метрики — это первый шаг цикла (и часть второго). Без них невозможно замкнуть обратную связь для эффективного управления проектом.

Говоря про уровни планирования, метрики помогают:

- На оперативном уровне быстрее разбираться с форс-мажорными ситуациями.
- На тактическом уровне устранять негативные тенденции (вроде деградации производительности из-за роста объёма данных) до момента, когда они срабатывают.
- На стратегическом уровне планировать дорогие изменения в архитектуре и инфраструктуре.

Из этого не слудет, что первым коммитом должна идти реализация метрик — всё хорошо в меру.

При разработке прототипа и даже при начале эксплуатации можно опираться на свой опыт, чуйку, периодические ручные проверки состояния системы, дисциплинированность и компетентность команды. В конце-концов, плохо работающая бизнес-логика без метрик обычно лучше нереализованной бизнес-логики с крутыми метриками :-D

Но общая логика примерно следующая: чем сильнее последствия срабатывания рисков тем больше метрик вам надо.

## За метриками надо следить глазами

Метрики нужны не только для того, чтобы смотреть на них во время борьбы с инцидентами или планирования долгосрочных изменений.

Метрики нужны, чтобы демонстрировать вам динамику проекта, его внутреннюю жизнь.

Обладая привычкой периодически смотреть на метрики глазами, вы запустите [цикл уточнения вашей ментальной модели]{post:life-and-work-with-models} проекта. А точная менатльная модель проекта — это ваше понимания его — залог успешной работы.

## Вы не знаете какие метрики вам потребуются

Есть базовые метрики, которые нужны всем или почти всем. Например, [персентили](https://ru.wikipedia.org/wiki/Процентиль) времени ответа на запросы, количество запросов в секунду, количество ошибок, количество запросов на каждый из эндпоинтов API, размеры базы данных, таблиц, индексов и так далее.

Но базовые метрики, что логично, позволяют реагировать только на базовые проблемы. Это уже много, но каждый проект уникален, более того, уникален путь разработки, поэтому кроме базовых проблем у вас обязательно будут проблемы уникальные для вас. И задачи уникальные для вас.

Для примера, на моём последнем месте работы у нас были реализованы [распределённые транзакции](https://en.wikipedia.org/wiki/Distributed_transaction) для обработки платежей с помощью [Orchestration-based saga](https://microservices.io/patterns/data/saga.html в форме [FSM](https://ru.wikipedia.org/wiki/Конечный_автомат) хранящих своё состояние в базе. В какой-то момент для нас оказалось полезным видеть динамику изменения распределения FSM по состояниям.

Проблема в том, что метрики, в большинстве случаев, при добавлении новой метрики у неё не будет истории. А история изменений — это то, что делает метрики реально полезными. Если вы столкнулись с проблемой и видите её на метриках, то вам важны не только их текущие показатели, но и динамика: направление изменений, цикличность, сезонность и так далее.

Поэтому, разумно следовать следующим эвристикам:

- Много метрик лучше, чем мало.
- Если вам придумалась метрика и добавить её несложно — добавьте.
- Если у вас есть критический компонент в системе, включите режим параноика и облажите его метриками сверху до низу.

Поэтому я очень нелюблю SaaS-решения, которые берут оплату за количество уникальных метрик. Особенно, с учётом определения уникальности по сочетания названия метрики с сочетанием всех возможных её меток/тегов. Использование таких сервисов заставляет разработчиков заниматься проектированием метрик, а не разработкой приложения.

## Приложение не должно знать о вашем Service Level Agreement

Задача вашего приложения — работать и давать вам чёткие честные измерения своего состояния — быть источником правды. Что делать с этими измерениями — это уже ответсвенность разработчика и инфраструктуры, которую он строит вокруг приложения.

В задачи вашего приложения не должны входить расчёты персентилей, уменьшение точности метрик, их аггрерирование и так далее.

Во-первых, это не относится к бизнес-логике, а значи не несёт пользы пользователям.

Во-вторых, это усложняет приложение, что усложняет его модификацию и поддержку. Не то, чтобы критически, но всё-таки усложняет.

В-третьих, это усложняет и замедляет внесения изменений в метрики. Для примера, если вы используете Prometheus и отдаёте ему гистограммы:

- Для любого изменения гистограмм вам надо будет, в лучшем случае, обновить конфиги приложения на проде. В худшем — обновить его код, а значит сделать полноценный релиз. И будем честными, вы будете релизить, потому что забили на вынос параметров метрик в конфиги.
- Если вам внезапно понадобится разделить метрики по разным типам гистограмм (например, одна для времени быстрых операций, другая — для медленных), то вам придётся менять код приложения и это могут быть не совсем тривиальные изменения.

В-четвёртых, если у вас может быть несколько версий на проде (a/b тесты, замедленная раскатка релиза, демо-сервера, etc), то у вас может образоваться неразгребаемая каша из несовместимых метрик, что сделает невозможным их анализ.

Поэтому мне несимпатичен подход Prometheus к сбору предагрегированных метрик, я просто не понимаю как с ним можно нормально жить.

## Приложение должно тольку пушить (push) метрики

Не пытаться их хранить, чтобы потом кто-то их собрал или не собрал.

Во-первых, могут и не собрать по огромному количеству причин. Например, из-за того, что приложение упало за секунду до того, как до него добрался Prometheus.

Во-вторых, до всего ваш коллектор всё равно не доберётся, как бы вы не старались. Всегда есть автономные скрипты, которые тоже нужно мерять. Иногда могут возникнуть и проблемы с границами периметров безопасности или с границами систем. Поэтому всё равно придётся делать push логику для частных случаев, а значит делать работу дважды, усложнять инфраструктуру.

Это ещё одна причина, почему мне несимпатичен pull подход Prometheus к сбору метрик.

## Метрики и логи — одно целое

И то и другое — [телеметрия](https://ru.wikipedia.org/wiki/Телеметрия).

Сообщение о метрике может быть записью в логах и запись в логах можно интерпретировать как метрику.

Поэтому, для нужд приложения, нет смысла их разделять. Пытаясь работать с метриками и логами по-разному вы усложняете архитектуру, инфраструктуру и свою жизнь в целом.

Учитывая текущую (сугубо позитивную) моду на структурированные логи (это когда каждая запись в логах имеет строгий формат, обычно JSON), имеет смысл просто писать всё как логи на stdout.

В таком случае от метрик на стороне приложения остаётся не много.

Первое — какая-нибудь функция-обёртка над логирования в духе

```
def measure(event: str, value: int | float):
    logger.info(event, m_kind="measure", m_value=value)
```

Второе — какой-нибудь механизм задания меток/тегов **для всех записей в лог**, если вы планируете их использовать.

## Реализация меток на бэкенде Feeds Fun

1. Я добавил метод `measure` прямо в класс логера, благодаря чему могу регистрировать изменения везде, где есть логер.
2. Для меток использую контекст процессор устанавливающий [contextvars](https://docs.python.org/3/library/contextvars.html) в сочетании с [отдельным процессором логов](https://www.structlog.org/en/stable/api.html#structlog.contextvars.merge_contextvars) и из [structlog](https://www.structlog.org/en/stable/), который **мержит метки каждую запись логов**.
3. Все логи пишутся на stdout.

Выглядит это примерно так ([полный исходник](https://github.com/Tiendil/feeds.fun/blob/main/ffun/ffun/core/logging.py)):

```
LabelValue = int | str | None

class MeasuringBoundLoggerMixin:

    def measure(self, event: str, value: float | int, **labels: LabelValue) -> Any:
        if not labels:
            return self.info(event, m_kind="measure", m_value=value)  # type: ignore

        with bound_measure_labels(**labels):
            return self.info(event, m_kind="measure", m_value=value)  # type: ignore

    @contextlib.contextmanager
    def measure_block_time(self, event: str, **labels: LabelValue) -> Iterator[dict[str, LabelValue]]:
        started_at = time.monotonic()

        extra_labels: dict[str, LabelValue] = {}

        with bound_measure_labels(**labels):
            try:
                yield extra_labels
            finally:
                self.measure(event, time.monotonic() - started_at, **extra_labels)


@contextlib.contextmanager
def bound_measure_labels(**labels: LabelValue) -> Iterator[None]:
    if not labels:
        yield
        return

    bound_vars = structlog_contextvars.get_contextvars()

    if "m_labels" in bound_vars:
        if labels.keys() & bound_vars["m_labels"].keys():
            raise errors.DuplicatedMeasureLabels()

        new_labels = copy.copy(bound_vars["m_labels"])

    else:
        new_labels = {}

    new_labels.update(labels)

    with structlog_contextvars.bound_contextvars(m_labels=new_labels):
        yield
```

## Обработка метрк на бэкенде Feeds Fun

Что происходит с метриками после их записи в лог вы могли видеть на заглавной картинке. На всякий случай продублирую её тут.

/// brigid-images
src = "./feeds-fun-metrics-schema.png"
alt = "Примерно так сейчас выглядит сборка метрки в Feeds Fun. Loki (или что-нибудь похожее) пока не развёрнут, но ожидается в будущем."
///

Итак:

1. Приложение и все утилиты запускаются в [Docker](https://www.docker.com/) контейнерах. Вообще, в [Docker Swarm](https://docs.docker.com/engine/swarm/), но это не важно.
2. [Vector](https://vector.dev/) настроен собирать логи из докера и делать с ними разные штуки:
    - Часть логов преобразует в метрики и аггегирует по правилам Prometheus.
    - Все логи будет посылать в какой-ниьбудь [Loki](https://grafana.com/oss/loki/), но чуть позже, пока не тратил время на эту часть.
3. [Prometheus](https://prometheus.io/) ходит на одну точку за всеми метриками всех приложений.
4. [Grafan](https://grafana.com/) рисует дашборды по метрикам из Prometheus.

Соответственно, большинство манипуляций с метриками: изменение структуры bucket в гистограммах, создание новых метрик, редактирование их меток, удаление метрик, etc. я могу делть изменя конфиг Vector-а и никак не затрагивая работу бизнес-логики.

Удобно и то, что определение источников логов в Vector можно определять достаточно гибко. Нарпимер, в моём случае логи приложения определяются по префиксу имени image контейнера. Соответственно, чтобы новое я не запустил на бэке (новые сервисы, cron задачи, etc), пока у них будет тот же базовый image, их логи и метрики будут распознаваться автоматически.

Также, на мой взгляд, удобно и то, что в случае разворачивания новых серверов / контейнеров / окружений мне надо будет только настроить потоки данных в Vector (или между экземплярами Vector), а не менять конфигурацию Prometheus или учить его находить сервисы.
