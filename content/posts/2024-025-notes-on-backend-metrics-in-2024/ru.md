---
title = "Заметки о метриках бэкенда в 2024"
tags = ["practice", "development", "backend", "feeds-fun"]
published_at = "2024-10-27T12:00:00+00:00"
seo_description = "Некоторые заметки о сборе метри на бэке в 2024 году."
seo_image = "./feeds-fun-metrics-schema.png"
---

/// brigid-images
src = "./feeds-fun-metrics-schema.png"
caption = "Примерно так сейчас выглядит сбор метрик в Feeds Fun. Loki добавлен как возможный следующий шаг развития инфраструктуры."
///

Раз в 2-3 года у меня начинается новый проект и приходится «заново» разбираться с метриками — как их собирать и рисовать на этот раз. Не то чтобы это единственное, с чем приходится разбираться, — обычно меняется много всего, но подход к метрикам меняется гарантировано.

Я [слал метрики по UDP]{post:collect-metrics-in-linux} в [Graphite](https://graphiteapp.org/) (в 2024, пост из 2015 выглядит забавно), использовал SaaS-решения вроде [Datadog](https://www.datadoghq.com/) и [New Relic](https://newrelic.com/), аггрегировал метрики в приложении, чтобы их забирал [Prometheus](https://prometheus.io/), писал метрики в логи для [AWS CloudWatch](https://aws.amazon.com/cloudwatch/).

И всегда всплывали нюансы:

- Особенности технологий проекта и его архитектуры накладывают внезапные ограничения.
- Технические требования к полноте, корректности и точности метрик сталкиваются с бизнес ограничениями на стоимость поддержки инфраструктуры.
- Всплывают специализированные базы данных для хранения [time series](https://ru.wikipedia.org/wiki/Временной_ряд), с которыми разработчики бэка редко имеют дело напрямую.
- Не говоря уже об идеалогии и личных предпочтениях разработчиков.

Поэтому нет одного идеального способа собирать метрики. Более того, разнообразие подходов вкупе с быстрой эволюцией всей области привело к появлению огромого количества open-source кирпичей, из которых можно собрать любого франкенштейна.

Поэтому, когда дошли руки для реализации метрик в [Feeds Fun](https://feeds.fun/), мне пришлось в очередной раз потратить несколько дней на актуализацию знаний и наведение порядка в голове.

В этом посте я поделюсь некоторыми своими мыслями и решением, которое выбрал для себя. Но не в форме урока, а в форме тезисов о темах к которым неравнодушен именно я.

<!-- more -->

## Метрики — базовый инструмент для управления техническим состоянием проекта на оперативном, тактическом и стратегическом уровнях

Метрики — это буквально глаза разработчика. Без них невозможно видеть как актуальную техническую ситуацию на проекте так и её долгосрочные тренды.

Если брать классический цикл из системной инженерии (и других [мемплексов]{post:genes-memes-memeplexes}):

1. сбор данных;
2. анализ данных;
3. синтез (принятие) решения;
4. реализация решения;

то метрики — это первый шаг цикла (и часть второго). Без них невозможно замкнуть обратную связь для эффективного управления проектом.

Говоря про уровни планирования, метрики помогают:

- На оперативном уровне быстрее разбираться с форс-мажорными ситуациями.
- На тактическом уровне устранять негативные тенденции (вроде деградации производительности из-за роста объёма данных) до момента, когда они срабатывают.
- На стратегическом уровне планировать дорогие изменения в архитектуре и инфраструктуре. Например, обосновывать необходимость шардирования базы или внедрения очередей.

Конечно, из этого не слудет, что первым коммитом должна идти реализация метрик — всё хорошо в меру.

При разработке прототипа и даже при начале эксплуатации можно опираться на свой опыт, чуйку, периодические ручные проверки состояния системы, дисциплинированность и компетентность команды. В конце-концов, плохо работающая бизнес-логика без метрик обычно лучше нереализованной бизнес-логики с крутыми метриками :-D

Но общая идея примерно следующая: чем сильнее последствия срабатывания рисков тем больше метрик вам надо.

## За метриками надо следить глазами

Метрики нужны не только чтобы смотреть на них во время борьбы с инцидентами или планирования долгосрочных изменений.

Метрики демонстрируют вам динамику проекта, его внутреннюю жизнь.

Привычка периодически смотреть на метрики глазами запускает цикл обратно связи для [уточнения вашей ментальной модели]{post:life-and-work-with-models} проекта. А точная ментальная модель — залог вашей успешной работы, скорости и качества принимаемых решений.

## Вы не знаете какие метрики вам потребуются

Есть базовые метрики, которые нужны всем или почти всем. Например, [персентили](https://ru.wikipedia.org/wiki/Процентиль) времени ответа на запросы, количество запросов в секунду, количество ошибок, количество запросов на каждый из эндпоинтов API, размеры базы данных, таблиц, индексов и так далее.

Но базовые метрики, что логично, позволяют реагировать только на базовые проблемы. Это уже много, но каждый проект уникален, уникален путь его разработки, поэтому кроме базовых проблем у вас обязательно возникнут проблемы уникальные для вас, задачи уникальные для вас.

Для примера, на моём последнем месте работы мы реализовали [распределённые транзакции](https://en.wikipedia.org/wiki/Distributed_transaction) для обработки платежей с помощью [Orchestration-based saga](https://microservices.io/patterns/data/saga.html) в форме [FSM](https://ru.wikipedia.org/wiki/Конечный_автомат). В какой-то момент нам потребовалось видеть динамику изменения распределения FSM по состояниям.

К сожалению, в большинстве случаев, при добавлении новой метрики у неё не будет истории. А история изменений — это то, что делает метрики реально полезными. Если вы столкнулись с проблемой и видите её на метриках, то вам важны не только их текущие показатели, но и динамика: направление изменений, цикличность, сезонность и так далее.

Поэтому, разумно следовать следующим эвристикам:

- Много метрик лучше, чем мало.
- Если вам придумалась метрика и добавить её легко — добавьте.
- Если у вас есть критический компонент в системе, включите режим параноика и облажите его метриками сверху до низу.

Поэтому я очень нелюблю SaaS-решения, которые берут оплату за количество уникальных метрик. Особенно, с учётом определения уникальности по сочетанию названия метрики со всеми возможными комбинациями её меток/тегов. Использование таких сервисов заставляет разработчиков заниматься проектированием метрик вместо разработкой приложения.

## История метрик должна быть долгой

В моей практике я часто сталкивался с утвержденями в духе «2 недели истории метрик достаточно». Аргументация заключается в том, что за две недели всплывут любые существенные проблемы. А если проблем не было, то и долгая история не нужна — сэкономим деньги.

Это в корне неверно по следующим причинам:

- [Люди совершают ошибки]{post:life-and-work-with-mistakes}: лажают, забывают, отвлекаются, пилят бизнес-фичи в кранче, уходят в отпуск. Из того, что никто за две недели не заметил проблему, не значит, что её нет или что она несущественная.
- Наши системы не идеальны, особенно вспомогательные вроде мониторинга. Часто мониторинг обсуждают с позиции «идеальной системы когда мы её построим» — в которой уже есть все возможные метрики и все возможные детекторы аномалий. Но ни у кого никогда не было идеальной системы мониторинга. В большинстве случае она вообще делается по остаточному принципу, так как не несёт прямой пользу никому кроме технарей.
- Многие процессы в жизни нелинейны. Проблема легко может нарастать [экспоненциально](https://ru.wikipedia.org/wiki/Экспоненциальный_рост). Например, полгода незаметно для всех прибавлять по проценту в день к длительности запроса, после чего за неделю увеличить её в 20 раз. С короткой историей мы не сможем заметить тренд вовремя (наклон графика на коротком интервале будет слабо незаметен), но и не сможем быстро найти точку начала тренда.

## Приложение не должно знать о вашем Service Level Agreement

Задача вашего приложения — работать и давать вам чёткие честные измерения своего состояния — быть источником правды. Что делать с этими измерениями — это уже ответсвенность разработчика и инфраструктуры, которую он строит вокруг приложения.

В задачи вашего приложения не должны входить расчёты персентилей, уменьшение точности метрик, их аггрерирование и так далее.

Во-первых, это не относится к бизнес-логике, а значи не несёт пользы пользователям.

Во-вторых, это усложняет приложение, что усложняет его модификацию и поддержку. Не то, чтобы критически, но всё-таки усложняет.

В-третьих, это усложняет и замедляет внесения изменений в метрики. Для примера, если вы используете Prometheus и отдаёте ему гистограммы:

- Для любого изменения гистограмм вам надо будет, в лучшем случае, обновить конфиги приложения на проде. В худшем — обновить его код, а значит сделать полноценный релиз. И будем честными, вы будете релизить, потому что забили на вынос параметров метрик в конфиги.
- Если вам внезапно понадобится разделить метрики по разным типам гистограмм (например, одна для времени быстрых операций, другая — для медленных), то вам придётся менять код приложения и это могут быть не совсем тривиальные изменения.

В-четвёртых, если у вас может быть несколько версий на проде (a/b тесты, замедленная раскатка релиза, демо-сервера, etc), то у вас может образоваться неразгребаемая каша из несовместимых метрик, что сделает невозможным их анализ.

Поэтому мне несимпатичен подход Prometheus к сбору предагрегированных метрик, я просто не понимаю как с ним можно нормально жить.

## Приложение должно тольку пушить (push) метрики

Не пытаться их хранить, чтобы потом кто-то их собрал или не собрал.

Во-первых, могут и не собрать по огромному количеству причин. Например, из-за того, что приложение упало за секунду до того, как до него добрался Prometheus.

Во-вторых, до всего ваш коллектор всё равно не доберётся, как бы вы не старались. Всегда есть автономные скрипты, которые тоже нужно мерять. Иногда могут возникнуть и проблемы с границами периметров безопасности или с границами систем. Поэтому всё равно придётся делать push логику для частных случаев, а значит делать работу дважды, усложнять инфраструктуру.

Это ещё одна причина, почему мне несимпатичен pull подход Prometheus к сбору метрик.

## Метрики и логи — одно целое

И то и другое — [телеметрия](https://ru.wikipedia.org/wiki/Телеметрия).

Сообщение о метрике может быть записью в логах и запись в логах можно интерпретировать как метрику.

Поэтому, для нужд приложения, нет смысла их разделять. Пытаясь работать с метриками и логами по-разному вы усложняете архитектуру, инфраструктуру и свою жизнь в целом.

Учитывая текущую (сугубо позитивную) моду на структурированные логи (это когда каждая запись в логах имеет строгий формат, обычно JSON), имеет смысл просто писать всё как логи на stdout.

В таком случае от метрик на стороне приложения остаётся не много.

Первое — какая-нибудь функция-обёртка над логирования в духе

```
def measure(event: str, value: int | float):
    logger.info(event, m_kind="measure", m_value=value)
```

Второе — какой-нибудь механизм задания меток/тегов **для всех записей в лог**, если вы планируете их использовать.

## Реализация меток на бэкенде Feeds Fun

1. Я добавил метод `measure` прямо в класс логера, благодаря чему могу регистрировать изменения везде, где есть логер.
2. Для меток использую контекст процессор устанавливающий [contextvars](https://docs.python.org/3/library/contextvars.html) в сочетании с [отдельным процессором логов](https://www.structlog.org/en/stable/api.html#structlog.contextvars.merge_contextvars) и из [structlog](https://www.structlog.org/en/stable/), который **мержит метки каждую запись логов**.
3. Все логи пишутся на stdout.

Выглядит это примерно так ([полный исходник](https://github.com/Tiendil/feeds.fun/blob/main/ffun/ffun/core/logging.py)):

```
LabelValue = int | str | None

class MeasuringBoundLoggerMixin:

    def measure(self,
                event: str,
                value: float | int,
                **labels: LabelValue) -> Any:

        if not labels:
            return self.info(event, m_kind="measure", m_value=value)

        with bound_measure_labels(**labels):
            return self.info(event, m_kind="measure", m_value=value)

    @contextlib.contextmanager
    def measure_block_time(self,
                           event: str,
                           **labels: LabelValue) -> Iterator[dict[str, LabelValue]]:
        started_at = time.monotonic()

        extra_labels: dict[str, LabelValue] = {}

        with bound_measure_labels(**labels):
            try:
                yield extra_labels
            finally:
                self.measure(event,
                             time.monotonic() - started_at,
                             **extra_labels)


@contextlib.contextmanager
def bound_measure_labels(**labels: LabelValue) -> Iterator[None]:
    if not labels:
        yield
        return

    bound_vars = structlog_contextvars.get_contextvars()

    if "m_labels" in bound_vars:
        if labels.keys() & bound_vars["m_labels"].keys():
            raise errors.DuplicatedMeasureLabels()

        new_labels = copy.copy(bound_vars["m_labels"])

    else:
        new_labels = {}

    new_labels.update(labels)

    with structlog_contextvars.bound_contextvars(m_labels=new_labels):
        yield
```

## Обработка метрик на бэкенде Feeds Fun

Что происходит с метриками после их записи в лог вы могли видеть на заглавной картинке. На всякий случай продублирую её тут.

/// brigid-images
src = "./feeds-fun-metrics-schema.png"
caption = "Примерно так сейчас выглядит сборка метрки в Feeds Fun. Loki (или что-нибудь похожее) пока не развёрнут, но ожидается в будущем."
///

Итак:

1. Приложение и все утилиты запускаются в [Docker](https://www.docker.com/) контейнерах. Вообще, в [Docker Swarm](https://docs.docker.com/engine/swarm/), но это не важно.
2. [Vector](https://vector.dev/) настроен собирать логи из докера и делать с ними разные штуки:
    - Часть логов преобразует в метрики и аггегирует по правилам Prometheus.
    - Все логи будет посылать в какой-ниьбудь [Loki](https://grafana.com/oss/loki/), но чуть позже, пока не тратил время на эту часть.
3. [Prometheus](https://prometheus.io/) ходит на одну точку за всеми метриками всех приложений.
4. [Grafan](https://grafana.com/) рисует дашборды по метрикам из Prometheus.

Соответственно, большинство манипуляций с метриками: изменение структуры bucket в гистограммах, создание новых метрик, редактирование их меток, удаление метрик, etc. я могу делть изменя конфиг Vector-а и никак не затрагивая работу бизнес-логики.

Удобно и то, что определение источников логов в Vector можно определять достаточно гибко. Нарпимер, в моём случае логи приложения определяются по префиксу имени image контейнера. Соответственно, чтобы новое я не запустил на бэке (новые сервисы, cron задачи, etc), пока у них будет тот же базовый image, их логи и метрики будут распознаваться автоматически.

Также, на мой взгляд, удобно и то, что в случае разворачивания новых серверов / контейнеров / окружений мне надо будет только настроить потоки данных в Vector (или между экземплярами Vector), а не менять конфигурацию Prometheus или учить его находить сервисы.
