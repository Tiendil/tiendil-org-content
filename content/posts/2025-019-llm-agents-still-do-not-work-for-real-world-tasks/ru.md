title = "LLM агенты всё ещё не подходят для реальных задач"
tags = [ "practice", "development", ""backend", "neural-networks", "scientific-papers"]
published_at = "2025-11-08T12:00:00+00:00"
seo_description = "В очередной раз попробовал LLM агенты на реальных рутинных задачах программирования, в очередной раз не помогли."
seo_image = "./cover.jpg"
---

/// brigid-images
src = "./cover.jpg"
caption = "AI агенты показывают результат своей работы программисту (с) ChatGPT & Hieronymus Bosch."
///

На это неделе протестил LLM на реальных задачах из своего программирования. Опять.

<!-- more -->

**Первая задача** — конвертирование конфигов аутентификационных прокси. Я вручную сделал конфиги для [Apache APISIX](https://apisix.apache.org/) и хотел, чтобы ChatGPT побыстрому сделал мне конфиги для полностью аналогичной логики для [Pomerium](https://www.pomerium.com/) и [OAuth2-proxy](https://oauth2-proxy.github.io/oauth2-proxy/).

Задача, на мой взгляд, максимально подходящая для автоматизации, более подходящую придумать сложно:

- Концептуально не сложная — не надо ничего выдумывать, вся необходимая логика полностью описана.
- Много монотонной работы с информацией — сложно для человека, просто для машины — надо вычитать много (не сложной, но запутанной) информации, чтобы правильно написать новые конфиги.
- По-сути, перевод с одного технического языка на другой.

Результат — провал — итоговые конфиги в обоих случаях **одноверменно**:

- Были нерабочими (прокси не запускались вообще).
- Содержали устаревшие или неправильные директивы.
- Не соответствовали логике, описанной в исходных конфигам.

**Вторая задача** — подготовить шаблон frontend приложения для [vue3](https://vuejs.org/): создать приложение, поставить [tailwindcss](https://tailwindcss.com/), поставить одну специфическую библиотеку — [dockview](https://dockview.dev/) — сделать пару тестовых компонентов. В этот раз использовал Copilot Agents. Просто хотел сэкономить своё время, плюс это последний по приоритету проект, который я мечтаю разрабатывать в духе вайб кодинга, но всё не получатся :-)

Результат — провал — пакеты поставлены, но я бы не назвал их нормально сконфигурированными, нужный GUI элементарно не отображался. Зато Copilot сделал красивое README со скриншотом пустой страницы и, что забавно, пытался меня убедить, что хоть скрин и пустой, всё на самом деле работает, просто скрины правильные потерялись где-то в tmp каталогах.

Обе задачи — это максимально рутинные штуки уровня усидчивого мидла, может даже джуна — не надо быть семи пядей во лбу, чтобы их сделать.

Кстати, вот недавно и исследование появилось, что [LLM-агенты эффективны примерно никак — справляются с около 2.5% реальных экономических задач](https://arxiv.org/abs/2510.26787).

У меня есть гипотеза, откуда весь этот хайп по поводу вайб-кодинга с помощью LLM агентов:

- Люди, которые делают LLM-ки — исследователи — у них мало производственного опыта.
- Люди, которые делают бенчмарки LLM-ок — тоже исследователи.
- Для исследователей работа программиста — это нафигачить крутую сортировку по памяти, или обход дерева хитрый для экономии двух тактов процессора в час.
- В итоге все эти LLM тюнятся не в ту сторону и оптимизируются не по тем метрикам.
- Потом это всё проходит через наших любимых ~~лидеров индустрии~~ стартаперов, которые отчасти не понимают, что автоматизация была и до ИИ (отчего приписывают её успехи новым инструментам), отчасти открыто врут (так как нельзя останавливать поток денег).

Всё это создаёт настолько загрязнённое информационное поле, что реальное положение дел становится неразличимо.

И ведь это не первый случай за последние десятилетия: блокчейн точно также тонул в хайпе, в итоге мир не перевернулся, но мы получили «ещё одну полезную технологию». До блокчейна были более мелкие хайповые волны, вроде NoSQL, нанотрубок (я даже видел сайт, который предлагал их грузовиками отгружать!), даже Ajax (a.k.a. web 2.0) проходил через эту стадию.
