---
title = "Пределы прогресса"
tags = ["theory", "neural-networks", "ai-notes-2024"]
series = "ai-notes-2024"
published_at = "2024-11-23T17:00:00+00:00"
seo_description = "TODO"
seo_image = ""
---

TODO: tags

Продолжаю заметки об ИИ на конец 2024 года.

/// brigid-series
tag = "ai-notes-2024"
///

Пришло время поговорить о самой хайповой, самой животрипещущей теме: доколе будет лететь текущий прогресс? Ждёт ли нас сингулярность в 2025 году или всё останется как прежде? Когда же наконец появится наш бог из металла и ~~силикона~~ кремния?

Большим искушением будет сказать что-то вдухе «да, будет сингулярность, пора строить алтари для процессоров» или «нет, закончилось уже всё, глупые машины останутся глупыми машинами».

Поддавшись этому искушению, я долго и безрезультатно пытался накатать версию этого эссе, но в итоге пришёл к мысли, что нужно смотреть шире. Затрагиваемая область слишком большая, чтобы можно было ткнуть пальцем и сказать «всё идёт сюда». Точнее ткнуть-то можно, обосновать сложно. В частности потому, что одно и то же утверждение можно обосновывать по-разному, через разные призмы, и кажда из призм будет показывать только часть правды. Захломлять же пост повторением одного и того же с разных точек зрения не хочется.

Поэтому я решил описывать не конечную точку, а ограничения на пути к ней, которые уже видны или логически вытекают из текущей ситуации.

Иными словами: очертить пределы прогресса.

<!-- more -->

## Через призму поколений моделей

В прошлых постах мы обсудили два тезиса:

- Анализируя решения крупных разработчиков ИИ, таких как OpenAI или Google, мы можем делать довольно точные предположения о состоянии этой области знаний.
- Весь текущий прогресс стоит на одной конкретной базовой технологии — генеративных базах знаний, которые есть большие статистические модели.

Давайте посмотрим, как эволюционировали топовые релизации этих моделей.

Идеальным примером для нас будет серия моделей от OpenAI: каждая новая модель буквально соответствует этапу развития базовой технологии.

1. Юность — GPT-3 — до предела улучшаем модель с помощью масштабирования данных и эксплуатации железа.
2. Становление — GPT-4 — когда исчерпаны возможности экстенсивного развития, мы переходим на интенсивный путь максимальной адаптации архитектуры.
3. Зрелось — O1 — когда мы больше не можем **радикально** улучшить базовую систему, мы начинаем строить надсистему, в которой она является одним из элементов — это универсальный принцип разработки софта, да и не только. Таким же образом, например, развивались операционные системы. Chain-of-thought, на которую натюнена O1, как раз и является первой такой надсистемой, хоть и очень простой. Chain-of-thought, по сути, можно воспринимать как последовательное применение модели к одним и тем же данным с разными вводными. Следующим шагом, например, может быть специализация моделей (привет многоакторность).

Обращу ваше внимание на то, что изменение базовой модели — крайне дорогая операция. Модели не меняют просто по желанию, их меняют ровно тогда, когда выжать что-то новое из старой модели становится экономически нецелесообразно по сравнению с вложением средств в мовые подходы. Иными словами, когда достигнут предел развития старой модели.

Например, в какой-то момент стало нецелесорбразно вкладывать основные ресурсы в масштабирование данных и утилизацию железа и переключились на оптимизацию архитектуры.

ТУДУ: это же может быть и признаком «разворачивания» технологии, когда новые слои строятся на базе старых, но старые не прекращают развиваться? Но дают ли они радикальные улучшения, были ли примеры? Вроде нет.





### Прогресс замедляется / ресурс для быстрого роста заканчивается

TODO: Тут всё очень субъективно, надо это отметить.
TODO: оценивать всё буду в порядках (пусть будет степени 10), так как нас интересует именно качественные скачки.

Помня что вся текущая движуха идёт вокруг, де-факто, статистичесхих моделей, давайте подумаем как можно улучшать результаты таких моделей.

У меня в голове есть несколько концептуальных подходов:

- Увеличивая количество данных, на которых готовится модель — чем больше более-менее хороших данных, тем легче модели сойтись в правдивый оптимум.
- Улучшая данные, на которых готовится модель — чтобы ей были лучше видны закономерности.
- ~~Меняя~~ Усложняя базовую архитектуру модели, чтобы она лучше выявляла закономерности. Почему базовую, объясню ниже — есть нюанс.
- Увеличивая модель: больше параметров делает модель гибче, но требует больше данных и времени для обучения. Увеличение модели — то, что сделали в OpenAI и что привело к буму LLM.
- Запуская несколько моделей параллельно. Предполагая, что каждая модель обучена более-менее на одно и то же, мы можем ожидать что они будут совпадать в правильных предсказаниях, но будут давать разного рода ошибки, что позволяет отсеевать ошибки и, тем самым, улучшать итоговый результат.
- Специализация моделей (ТУДУ, как разные отделы мозга)

Давайте сначала посмотрим на перспективы каждого из них.

**Увеличение количества данных** — общедоступные данные скорее исчерпаны, особенно текстовые. Остаётся некоторая доля проприетарных данных (тексты и видео, защищённые авторским правом), но нет оснований утверждать, что их на порядок больше, чем общедоступных. Идут активные исследования в плане генерации искусственных данных для обучения, но пока генерация данных выглядит (для меня) скорее как способ закрытия частных случаев (у нас есть шаблон задачи по математике, давайте сгенерим 100500 её вариантов, чтобы LLM начала хорошо решать именно эту задачу по математике). Соответственно, улучшение тут возможно где-то на порядок в лучшем случае.

**Улучшение данных** — на мой взгляд, в этой области сейчас идёт большое движение, мы учимся готовить качественные данные для обучения нейронок и периодически появляются многообещающие сообщения «мы по-хитрому подготовили/почистили данные и наша нейронка показал значительное улучшение в качестве». Проблема с улучшение данных в том, что в нём есть предел — невозможно улучшать их бесконечно. В какой-то момент они станут очень хорошими и что тогда? Появятся условные [ISO стандарты](https://en.wikipedia.org/wiki/International_Organization_for_Standardization) по оформлению данных для обучения и после них существенного движения вперёд не будет. Перефразируя, на сколько ещё мы можем улучшить наши данные? порядок? два? три? На мой взгляд, три порядка — это уже много, в духе «все наши текущие данные говно».

**Усложнение архитектуры** — самый крутой путь. Но его правильнее разделить на два.

**Революционное усложнение архитектуры**. Например, появление [механизма attention](https://en.wikipedia.org/wiki/Attention_Is_All_You_Need) привело к смене парадигмы в архитектурах нейронок, что во многом обеспечило последующее ускорение в их развитии. Такие революционные изменения слабо предсказуемы, но имеют огромный эффект. Наличие гарантированного потока революционных изменений архитектуры обеспечило бы бесконечное улучшение нейронок. Но это, само-собой, не возможно:

- Подобные прорывы невозможно гарантировать, на текущий момент они абсолютно не гарантированы ни в одной из областей науки и техники.
- ТУДУ: Подобных прорывов что-то давно не было
- Даже при наличии потенциально прорывного изменения, нарушить статус-кво становится всё дороже и дороже: нужно не просто показать интересное изменений, но и продемонстрировать что оно превосходит старые решения в топовых моделях. Но тренировать топовые модели очень дорого, никто не станет сходу проверять каждое новое решение подобным образом. Вместо этого каждое новое решение вынуждено проходить всё более долгий и тернистый путь из грязи в князи, необходимо ставить всё больше экспериментов, убеждать всё больше людей.

**Эволюционное усложнение архитектуры**. Любую сырыую архитектуру можно тюнить довольно долго и, иногда, дёшево. Такой тюнинг может быть довольно эффективным. Для примера,

**Увеличение модели** —

**Запуск нескольких моделей** — ТУДУ: вот тут должен быть вывод с Mixture Of Expers и O1

**Специализация моделей** — Акторы (но не в текущем виде), но близко.


### Концептуальных изменений в технологиях в ближашие 5-10 лет не будет

`Generative Knowledge Base` сформировалась как технология и она будет определять движение прогресса в ближайшие годы.

По следующим причинам:

1. `GKB` на текущий момент имеет огромный потенциал для улучшения и оптимизации. На мой взгляд, 2-3 порядка есть в запасе. Есть направления эволюционного улучшения для каждой части технологии, начиная от подготовки данных и заканчивая удешевлением эксплуатации. Вкладывание ресурсов в эти направления даёт быстрый и более-менее гарантированный результат. Поэтоу крупные игроки будут вкладывать ресурсы в эволюционные изменения, получая предсказуемый результат, который будет, в том числе, способствовать увеличению бонусов тех же директоров.
2. `GKB` позволяет решать множество задач, которые раньше были не решаемы, решались плохо или дорого. Эти задачи во многом видны, вкладывать ресурсы в их решение выгодно, вложения обещают большую отдачу. Все, кто не тренит свою большие модели будут вкладывать ресурсы в решение задач существующими моделями. Так как задач пока больше чем участников рынка и нет смысла искать что-то новое.
3. Разрабатывать радикально новые технологии очень дорого, рисковано и людей на это просто нет. Этим будут заниматься в академии, но ресурсов на ещё один прыжок веры, как сделала OpenAI с масштабированием обучения, никто не даст.

------

### Разница между «легко и понятно как сделать» и «непонятно и нелегко»

Очень быстро и очень медленно.

### Хайп по текущим достижениям

- Сдача школьных и вузовских экзаменов не показатель интеллекта. В текущем контексте это показатель качественного ообучения. Если бы в школьников вкладывали столько же бабла, сколько в нейронки, то школьники бы рвали эти экзамены как тузик грелку. Для примера, заканчивая школу я за 3 месяца с репетитором подтянул знание русского языка с 4 из 10 баллов (по тестам) до почти 9/10.
- С решением олимпиадных задач, даже международных, та же самая ситуация, они требуют от человека хорошей ассоциативной памяти, чтобы быстро приводить условия задач к шаблонному виду и решать их одним из натреннированных шаблонных способов. С ростом уровня олимпиады просто растёт количество шаблонов, этапов в алгоритме решения ну и сложности шагов. То есть это буквально тест работы семантической базы данных + алгоритмического мышления. Доказывать что-либо с нуля на олимпиадах по математике/информатики практически нет смысла. Ты либо знаешь это, либо нет. Если знаешь, следующий вопрос — сколько раз ты решал именно эту шаблонную задачу и как точно можешь воспроизвести её решение **в условиях стресса**.


## Морфологический анализ vs Statistics

Полный перебор vs Интуиции. Науку движет полный перебор, ограниченный интуицуией. Не одна интуиция.

## Сильный ИИ требует дифференциации механизмов/архитектур, не одной общей архитектуры

## Пределы текущих технологий



## Устойчивый [сильный ИИ](https://ru.wikipedia.org/wiki/Сильный_и_слабый_искусственные_интеллекты) пока не ждём

Сейчас есть несколько шкал для оценки сильности ИИ, например [вот](https://builtin.com/artificial-intelligence/types-of-artificial-intelligence), но все они сырые и нераспространённые. По крайней мере, на википедии я отдельной статьи на тему не нашёл.


- Семантическая статистическая база данных, а не ИИ, только один из блоков
  - идут научные статьи (и около научные в блогах) о том что такое сознание и о том, что текущие архитектуры нейронок — это не то
  - ИИ будет совокупностью разных технологий, разныз блоков, из которых у нас сейчас есть только часть. И эта архитектура будет много сложнее, чем всё, что у нас сейчас есть.
  - Отсебя: люди мыслят образами, а не строят предложения переусложнёнными марковскими цепями.
  - Если вы просите статистическую модель дать вам варианты, она даст наиболее вероятные варианты. Если попросите дать экспериментальные/нестандартные варианты, она даст вам наиболее вероятные экспериментальные/нестандартные. Это одна из самых больших моих проблем во взаимодействии с нейронками. Потому что морфологический анализ — это не статистический алгоритм, это полный перебор.
  - Нет сильных аргументов в пользу того, что у нас есть всё, чтобы сделать ИИ. Даже все компоненты, не говоря уже об архитектуре.
  - Что такое сильный ИИ пока не понятно. (ТУДУ: уровни силы ИИ, где-то были)
  - По сути, весь наш прогресс в стронг ИИ за последние лет 50 — это созданные несколько модулей, которые симулируют его кусочки, но как их собрать вместе, чем склеить, до сих пор никто не знает.
  - Решение задач олимпиад - маркетинговый булшит
  - Нужно ещё несколько прорывов в базах данных (эмбедингах) и коммуникациях между нейронками. И железе клнечно.
  - Просто комбинирование моделей не поможет, равно как и прямолинейное заигрывание с памятью. Необходим формат/протокол/система обмена мета алгоритмами мышления. Например, если попросить человека сделать резюме текста, то разные люди будут делать его по-разному: кто-то перескажет, своими словами, кто-то сначала выпишет тезисы, потом соединит их в текст, кто-то будет удалять лишнее, пока не останется только суть. И для разных текстов могут быть выгодны разные подходы.
  - Технологией ии будут не нейронки (по крайней мере в текущем виде) а что-то поверх нейронок.
  - Дообучение через промпты увеличивает касество, но не снимает проблему крайних случаев.
  - OpenAI прыкрыла алайгмент лабу

- Рабочих рук не хватает даже на текущий фронт работ, и их неоткуда брать. Квалификация для реальной разработки работающих ИИ систем требуется выше, чем для среднего программиста.
- Специализация нейронок
- Реальных прорывных продуктов в эксплуатации нет. Кроме чатов, копилотов (что круто) и маркетинговых/развлекательных штук. Копилоты — это ещё один инструмент для людей, инструментов у нас много (автомобили, например). Он многое изменит, но не концептуально. Чаты подрывают поиск. Остальное подрывает развлечения.
- Текущие статистические модели создают отдельную нишу инструемнтов, как IoT, или как шейдеры в геймдве, или как смартфоны. Они становятся неотъемлемой частью нашей жизни и рынка, но только расшрят его, не подрыват/отменяют существующие инструменты.
- Перешли на новый уровень масштабирования (o1), его стало экономически эффективнее делать, чем масштабировать сами нейронки.
- Процесс иниеграции первичных нейронрк в софт: кады, иде, фоторедакторы. По сути только начался. Пока он полностью не провернётся, не пройдёт через эволюционный отбор, прогрессировать во что то брлее сложное нет смысла, т. К. Не видно направление.
- Результат всего этого будет, скорее всего, в том, что во многих областях деятельности «просто станет лучше»
- LLM не сможет выразить/передать ваш опыт в чём-то, потому что он у вас пока только в голове, а не в общечеловеской базе знаний, которой становятся LLM. Соответственно, специалистам, учёным и прочим лидерам всё ещё придётся писать тексты самостоятельно, если они хотят туда новизну добавить. LLM в этом смогут помочь, но не более того.
- Началась специализация нейронок в виде «LLM-name coder», «LLM-name math», etc.
- Мы всё ещё не видим реально прорывных рабочиз приложений, серебряных пуль, за исключением чатов и генерации развлекалова (картинки, музыка). Ну, feeds.fun конечно есть ещё :-)
- Изменения будут как если бы людям вместо каменных орудий труда выдали те же, но железные.
- Уже было несколько технологий, которые должны были «подорвать всё», но не подорвали.
- Сравнить с внедрением ИИ

------

Предел возможностей текущих технологий уже виден

Сильного ИИ пока не ждём

Сингулярность пока не ждём

Массового внедрения ИИ пока не ждём

----------------

- Соответственно, если хотите сделать следующий прорыв, надо концетрировать усилия на взаиомдействии моделей, а не на тюнинге одной модели.
- Я бы ставил следующие прорывы на синтез неронок и DSL


ТУДУ:

- Заявления про переключения с страты ресурсов на обучение на трату ресурсов на исполнение — маркетинговый булшит. Это значит, что базовую модел больше не удаётся улучшать.
