---
title = "Мои GPT-шки и prompt engineering"
tags = ["theory", "practice", "development", "thinking", "exocortex"]
published_at = "2024-06-06T12:00:00+00:00"
seo_description = "Расскажу какие GPT я сделал для себя и как они работают"
seo_image = "./images/cover.jpg"
---

/// brigid-images
src = "./images/cover.jpg"
caption = "Понечки занимаются prompt engineering."
///

Я пользуюсь ChatGPT практически с момента выхода её четвёртой версии (то есть уже больше года). За это время хорошо набил руку в написании запросов к этой штуке.

В какой-то момент, OpenAI разрешили кастомизировать свой чат с помощью собственных текстовых инструкций (ищите в `Customize ChatGPT` в меню). Я постепенно дописывал туда команды и вот на днях разрешённый лимит был исчерапан :-)

Плюс, оказалось, что универсальный набор инструкций не получается, под каждую задачу их нужно подстраивать, что неудобно.

Поэтому покумекав, я решил вместо кастомезации своего чата, вынести все инструкции в GPT ботов. OpenAI называют их просто GPTs, по-русски буду называть их GPT-шками. По-сути, это такие же чаты, в которых больше лимит на кастомизированные инструкции плюс им можно залить дополнительные тексты как базу знаниий.

Когда-нибудь, я сделаю GPTшку для этого блога, а пока расскажу про двуз рабочих лошадок, которыми пользуюсь каждый день.

Для каждой будет ссылка и описание базового промпта с моими комментариями.

OpenAI недавно открыта стор GPT-шек, буду благодарен если пролайкаете мои.

<!-- more -->

## GPT "Expert"

Ссылка: https://chatgpt.com/g/g-c7aWJe3CN-expert

Как видите, на именование я времени не тратил. Может позже придумаю что-то более творческое.

Это мой основной инструмент, заточенный на чёткие глубокие ответы. Из недостатков: на нечёткие вопросы даёт очень нечёткие ответы, иногда приходится постараться с формулировками.

### Prompt

```
You should respond according to the next algorithm:

1. List 3 areas of the problem (e.g., "corporate laws", or "quantum physics.")
2. Define your role as an expert in these areas (e.g., "I am a professional game designer" or "I am a quantum physics researcher"). The definition must be "I am an expert in ... with a PhD in AREA_1, PhD in AREA_2, and PhD in AREA_3". AREA_N MUST be a real scientific area.
3. Reformulate the problem according to your expertise.
4. Break down the problem into a list of statements.
5. Describe what the ideal solution would look like.
5.1. List requirements.
5.2. List restrictions.
6. Describe the area of solution in multidimensional solution space.
6.1. List the qualitative dimensions of the solution.
6.2. Suggest cardinally new qualitative dimensions of the solution.
6.3. For each dimension, list the possible coordinates.
7. List subquestions that need to be answered before solving the problem.
8. Give short answers to the subquestions.
  - Consult StackOverflow for the answers related to the technical part of the problem.
  - Consult Wikipedia to all the other answers.
9. Write a detailed plan for the answer.
10. Write the answer according to the plan.
11. List standard alternative approaches to answer.
12. List creative alternative approaches to answer.

Additional requirements:

- You always follow the algorithm step-by-step.
- Do not skip steps; do not add steps.
- Before each step, output its description "as is".
- Execute instructions as exactly as possible.
- Do not focus on the mainstream.
- Prioritize precision of answer over simplicity.
- Use concrete, precise wording.
- Output text only as an outliner.
- Visually highlight main sections.
- If the user continues asking questions from the same area, skip steps 1-2.
```

Самое важное, что надо понимать в случае общения с современными LLM — это статистические модели. Очень большие и сложные статистические модели, но не более того. И сколько бы их не доучивали, они ими останутся. Есть эксперименты (почему-то не очень активные) по созданию обвеса для них, когда LLM является только одним из модулей в системе, но пока это только эксперименты.

Из статистической природы следует, что ответ вы получите тот, который видится модели наиболее вероятным. Не точным, не лучше всего относяийся к области решений, не самым глубоким, не полным, а именно вероятным. Поначалу разницу сложно увидеть, но со временем она всё больше бросается в глаза, особенно если вы задаёте сложные специализированные вопросы.

Поэтому большая часть promt engineering направлена на корректировку вероятностей.

Я это вижу так, что каждой инструкцией (формально каждым символом, но не будем загоняться) мы выставляем атрактор, этакий маячёк «сюда иди», или область «вот тут большая вероятность».

Общая структура моего промта заточена на то, чтобы сначала очертить крупную область решений, после чего заставить сеть самостоятельно (собственным ответом) методически сужать её.

1. Просим сеть напечатать несколько крупных областей знаний, которые относятся к вопросу. Это смещает вероятности от совсем левых областей и создаёт базу для следующего пункта.
2. Задаём роль, которая играет сеть, как эксперт. Поскольку нам интересны профессиональные глубокие ответы, мы указываем что хотим видеть текст, который с большой вероятностью будет произведён профессионалом с научной степенью.
3. Поскольку у нас, скорее всего, степеней таких нет, то наш вопрос может быть задан неверно. Поэтому просим у сети переписать вопрос на тот, который вероятно сформулировал бы профи с ролью из пункта 2.
4. Чем более точно и узко сформулирован вопрос, тем меньше разброс вероятностей у ответа на него. Поэтому бьём вопрос на составлыне части.
5. Аналогично делаем для ответа/решения. Поскольку мы немного шарим в системное инжинерии и мышлении, просим не просто описать идеальное решение, а конкретные его свойства.
6. На данном этапе сеть (с нашей помощью) хорошо очертила область, но можно ещё лучше. Мы можем попросить её сделать [морфологический анализ проблемы](https://ru.wikipedia.org/wiki/Морфологический_анализ_(изобретательство)). Я когда-то даже делал [софт для него](https://tiendil.github.io/morphologic/#/) но как-то не прижился прототип. Вручную морфологический анализ делать сложно и долго, даже в софте, а вот LLM делает его на раз-два, хотя и не идеальным образом. По моей задумке, морфологический аналаз должен смещать вероятности на с «решения в целом», на его составные части и, тем самым, увеличивая конкретность ответа. Но мне пока сложно оценить эффект.
7. Начинаем

Примечания:

- По возможности даём сети примеры ответа (пункт 1 и 2). Конкретный пример (даже шаблон) часто содержит больше конкретной информации, чем абстрактная формулировка (которая позволяет спект трактовок).
- Всегда используем научный/серьёзный сленг.
- Всегда просим сеть повторять задачи, чтобы ограничить неизбежное [накопление ошибки]{post:@choose-nearest-language:life-and-work-with-mistakes}. Без этого при выборе каждого следующего символа сеть будет опираться на всё более нечёткий контекст.
- Всегда стараемся просить несколько вариантов чего-то (несколько областей знаний, несколько тезисов, несколько PhD). Без этого


## Постскриптум

На всякий случай отмечу, что эти GPT-шки — мой основной инструмент работы с чатом, поэтому:

- Я их постоянно меняю на основе полученного опыта.
- Иногда я с ними эксперименирую.

Не удивляйтесь, если их логика будет слегка меняться.
