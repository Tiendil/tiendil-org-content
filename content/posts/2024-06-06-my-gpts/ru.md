---
title = "Мои GPT-шки и prompt engineering"
tags = ["theory", "practice", "development", "thinking", "exocortex"]
published_at = "2024-06-06T12:00:00+00:00"
seo_description = "Расскажу какие GPT я сделал для себя и как они работают"
seo_image = "./images/cover.jpg"
---

/// brigid-images
src = "./images/cover.jpg"
caption = "Понечки занимаются prompt engineering."
///

Я пользуюсь ChatGPT практически с момента выхода её четвёртой версии (то есть уже больше года). За это время хорошо набил руку в написании запросов к этой штуке.

В какой-то момент, OpenAI разрешили кастомизировать свой чат с помощью собственных текстовых инструкций (ищите в `Customize ChatGPT` в меню). Я постепенно дописывал туда команды и вот на днях разрешённый лимит был исчерапан :-)

Плюс, оказалось, что универсальный набор инструкций не получается, под каждую задачу их нужно подстраивать, что неудобно.

Поэтому покумекав, я решил вместо кастомезации своего чата, вынести все инструкции в GPT ботов. OpenAI называют их просто GPTs, по-русски буду называть их GPT-шками. По-сути, это такие же чаты, в которых больше лимит на кастомизированные инструкции плюс им можно залить дополнительные тексты как базу знаниий.

Когда-нибудь, я сделаю GPTшку для этого блога, а пока расскажу про двуз рабочих лошадок, которыми пользуюсь каждый день.

Для каждой будет ссылка и описание базового промпта с моими комментариями.

OpenAI недавно открыта стор GPT-шек, буду благодарен если пролайкаете мои.

<!-- more -->

## GPT "Expert"

Ссылка: https://chatgpt.com/g/g-c7aWJe3CN-expert

Как видите, на именование я времени не тратил. Может позже придумаю что-то более творческое.

Это мой основной инструмент, заточенный на чёткие глубокие ответы. Из недостатков: на нечёткие вопросы даёт очень нечёткие ответы, иногда приходится постараться с формулировками.

### Prompt

```
You should respond according to the next algorithm:

1. List 3 areas of the problem (e.g., "corporate laws", or "quantum physics.")
2. Define your role as an expert in these areas (e.g., "I am a professional game designer" or "I am a quantum physics researcher"). The definition must be "I am an expert in ... with a PhD in AREA_1, PhD in AREA_2, and PhD in AREA_3". AREA_N MUST be a real scientific area.
3. Reformulate the problem according to your expertise.
4. Break down the problem into a list of statements.
5. Describe what the ideal solution would look like.
5.1. List requirements.
5.2. List restrictions.
6. Describe the area of solution in multidimensional solution space.
6.1. List the qualitative dimensions of the solution.
6.2. Suggest cardinally new qualitative dimensions of the solution.
6.3. For each dimension, list the possible coordinates.
7. List subquestions that need to be answered before solving the problem.
8. Give short answers to the subquestions.
9. Write a detailed plan for the answer.
10. Write the answer according to the plan.
11. List standard alternative approaches to answer.
12. List creative alternative approaches to answer.

Additional requirements:

- You always follow the algorithm step-by-step.
- Do not skip steps; do not add steps.
- Before each step, output its description "as is".
- Execute instructions as exactly as possible.
- Do not focus on the mainstream.
- Prioritize precision of answer over simplicity.
- Use concrete, precise wording.
- Output text only as an outliner.
- Visually highlight main sections.
- If the user continues asking questions from the same area, skip steps 1-2.
```

Самое важное, что надо понимать в случае общения с современными LLM — это статистические модели. Очень большие и сложные статистические модели, но не более того. И сколько бы их не доучивали, они ими останутся. Есть эксперименты (почему-то не очень активные) по созданию обвеса для них, когда LLM является только одним из модулей в системе, но пока это только эксперименты.

Из статистической природы следует, что ответ вы получите тот, который видится модели наиболее вероятным. Не точным, не лучше всего относяийся к области решений, не самым глубоким, не полным, а именно вероятным. Поначалу разницу сложно увидеть, но со временем она всё больше бросается в глаза, особенно если вы задаёте сложные специализированные вопросы.

Поэтому большая часть promt engineering направлена на корректировку вероятностей.

Я это вижу так, что каждой инструкцией (формально каждым символом, но не будем загоняться) мы выставляем атрактор, этакий маячёк «сюда иди», или область «вот тут большая вероятность».

Высокоуровневая архитектура промпта. Каждый из пунктов базируется на результатах предыдущих.

1. Очерчиваем область вопроса.
2. Очерчиваем область ответа (пространство решений).
3. Очерчиваем область планов ответа.
4. Генерируем ответ по плану.
5. Перечисляем направления, в которые ещё можно было бы посмотреть.

Пояснения к каждому пункту промпта.

1. Просим сеть напечатать несколько крупных областей знаний, которые относятся к вопросу. Это смещает вероятности от совсем левых областей и создаёт базу для следующего пункта.
2. Задаём роль, которая играет сеть, как эксперт. Поскольку нам интересны профессиональные глубокие ответы, мы указываем что хотим видеть текст, который с большой вероятностью будет произведён профессионалом с научной степенью.
3. Поскольку у нас, скорее всего, степеней таких нет, то наш вопрос может быть задан неточно. Поэтому просим у сети переписать вопрос на тот, который вероятно сформулировал бы профи с ролью из пункта 2.
4. Чем более точно и узко сформулирован вопрос, тем меньше разброс вероятностей у ответа на него. Поэтому бьём вопрос на составлыне части.
5. Аналогично делаем для ответа/решения. Поскольку мы немного шарим в системной инжинерии и мышлении, просим не просто описать идеальное решение, а конкретные его свойства.
6. На данном этапе сеть (с нашей помощью) хорошо очертила пространство решений, но можно ещё лучше. Мы можем попросить её сделать [морфологический анализ проблемы](https://ru.wikipedia.org/wiki/Морфологический_анализ_(изобретательство)). Я когда-то даже делал [софт для него](https://tiendil.github.io/morphologic/#/) но как-то не прижился прототип. Вручную морфологический анализ делать сложно и долго, даже в софте, а вот LLM делает его на раз-два, хотя и не идеальным образом. По моей задумке, морфологический аналаз должен смещать вероятности с «решения в целом», на его составные части и, тем самым, увеличивать конкретность ответа. Но мне пока сложно оценить эффект.
7. Прежде чем формулировать план ответа, мы смещаем вероятности в сторону его составных частей.
8. По сути, продолжение предыдущего пункта. Задача разбита на два этапа, чтобы избежать накопления ошибки, которое происходит при выводе длинных текстов. Вместо одного большого полотна со списком ответов и вопросов, мы заставляем сеть выводить серию маленьких независимых текстов.
9. Сама генерация плана. По сути, тут мы просим сеть написать промпт/инструкцию для самой себя.
10. Просим написать сам ответ, причём сеть будет его генерировать также малыми кусками по этапам из предыдущего пункта.
11. Просим сгенерировать стандартные альтернативные подходы к ответу.
12. Просим сгенерировать креативные альтернативные подходы к ответу.

Примечания:

- По возможности даём сети примеры ответа (пункт 1 и 2). Конкретный пример (даже шаблон) часто содержит больше конкретной информации, чем абстрактная формулировка (которая позволяет спект трактовок).
- Всегда используем научный/серьёзный сленг.
- Всегда просим сеть повторять задачи, чтобы ограничить неизбежное [накопление ошибки]{post:@choose-nearest-language:life-and-work-with-mistakes}. Без этого при выборе каждого следующего символа сеть будет опираться на всё более нечёткий контекст.
- Всегда стараемся просить несколько вариантов чего-то (несколько областей знаний, несколько тезисов, несколько PhD). Без этого вы рискуете чрезмерно сузить область вероятных решений и вообще промазать по ответу.
- В промте можно найти несколько стандартных паттерном из prompt engineering, но я проектировал его в терминах паттерном, поэтому не буду пытаться их вычленить, дабы не заморачиваться с определнием их границ. Если вам интересны паттерны, есть отличный ресурс с ними: https://www.promptingguide.ai/


## Постскриптум

На всякий случай отмечу, что эти GPT-шки — мой основной инструмент работы с чатом, поэтому:

- Я их постоянно меняю на основе полученного опыта.
- Иногда я с ними эксперименирую.

Не удивляйтесь, если их логика будет слегка меняться.
