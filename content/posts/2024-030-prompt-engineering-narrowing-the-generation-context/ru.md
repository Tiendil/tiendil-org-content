---
title = "Prompt engineering: сужение контекста генерации"
tags = ["theory", "practice", "neural-networks", "development", "feeds-fun", "prompt-engineering", "interesting"]
published_at = "2024-16-13T17:00:00+00:00"
seo_description = "Рассказываю про подход к построению промптов, который позволил мне значительно улучшить результаты генерации тегов в feeds.fun"
seo_image = ""
---

Как вы знаете, одна из фич моей [читалки новостей](https://feeds.fun/) — автоматическая генерация тегов с помощью LLM. Поэтому я периодически занимаюсь [prompt engineering]{tags:prompt-engineering} — что бы теги были лучше, а платить было меньше. Типо прикладным, а не теоретическим :-D

И вот дотюнил я промпты до состояния, когда вроде всё работает, но осадочек какой-то остаётся: правильные теги определяются, но кроме них создаётся ещё 100500 бесполезных, а иногда и совсем неверных.

Вариантов действий в таких не много:

1. Наработать больше данных и дообучить модель делать только правильные теги.
2. Построить цепочку акторов, где один будет создавать теги, а другой — отсеивать лишние.
3. Попытаться как-то радикально переработать промпт.

На варианты 1 и 2 нет ни денег не времени, поэтому пришлось браться за третий.

Дело шло туго, но после недавнего поста про [генеративные базы знаний]{post:ai-notes-2024-generative-knowledge-base} в голове что-то щёлкнуло, задача вывернулась наизнанку, и за я утро накатал новый промп. который пока что показывает себя значительно лучше.

Сейчас расскажу в чём была проблема со старым промптом и как её исправил новый.

## Старый промпт
