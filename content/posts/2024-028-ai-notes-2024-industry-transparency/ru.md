---
title = "Заметки об ИИ в 2024: прозрачность индустрии"
tags = ["practice", "theory", "business"]
published_at = "2024-11-03T12:00:00+00:00"
seo_description = ""
seo_image = ""
---

<!-- TODO: description -->
<!-- TODO: tags -->
<!-- TODO: add image -->
<!-- TODO: add SEO image -->

Года полтора назад я опубликовал большой [прогноз об искусственном интеллекте]{post:silly-predictions-about-artificial-intelligence}. Почитайте, если ещё не читали — он довольно точный.

Недавно решил его дополнить, но большой целостный пост всё никак не выходит, поэтому будет серия заметок.

Начну с прозрачности индустрии.

У текущей движухи с ИИ есть несколько крутых особенностей, которые облегчают её анализ:

1. Малая задержка в получении информации об актуальном состоянии отрасли. Всё происходит публично: мы либо в моменте знаем кто из больших игроков что делает, либо узнаём в течении полугода-года.
2. Все крупные проекты ведутся опытными ИТ-бизнесменами, которые умеют считать деньги и потенциальную выгоду от их распределения. Поэтому направления усилий компаний хорошо корреклируют с оценкой перспективности технологий. И с перспективностью поднятия хайпа тоже, справедливости ради.
3. Обилие денег и нехватка рук специализированных разработчиков ведёт к тому, что архитектурой нейронок занимаются в последниюю очередь. Не в смысле вообще не занимаются, а в смысле, выберите близкую вам трактовку:

- Масштабируем всё, что можно масштабировать деньгами (железо, данные) прежде чем вкладываться в изменение базовой технологии.
- Выжимаем из текущих технологий всё, что можно, прежде чем переключаться на новые.

Менять базовую архитектуру нейронок дорого и рисковано. В случае ошибки потери будут не только в деньгах, но и во времени. Условная GPT-5 учится не только дорого, но долго.

Риск ошибки при смене архитектуры большой, так как пространство возможных архитектур огромно и большинство из них плохие — это справделиво для любой исследовательской и многих инженерных областей, не только для архитектур нейронок. Поиск эффективной архитектуры в этом пространстве стоит самого дорогого и невосполнимого ресурса — времени очень квалифицированных и очень редких специалистов. Это время сейчас практически не покупается за диньги. Например, есть версия, что [Google недавно купил стартап за 2.7 млрд$ только для того, чтобы забрать его основателей и core команду обратно к себе](https://www.linkedin.com/pulse/analyzing-googles-characterai-acquisition-sramana-mitra-iramc/).

А вот масштабировать железо и данные на порядки дешевле, потому что ~~Dev~~MLOps, разного рода data scientists и не топовых ML инженеров либо много, либо очень много, как и самого железа. Отсюда же идут влажения баснословных сумм в новые датацентры и железо — отмасштабировать производство на фабриках значительно проще и быстрее, чем отмасштабировать производство специалистов, которые в состоянии производить и тестировать новые архитектуры нейронок.

Соответственно, мы можем видеть:

- Как перспективность того или иного пути развития видят сильные мира сего, игнориуя маркетинговый туман, который они же нагоняют.
- Как потенциал конкретной архитектуры/технологии достигает (пред)пика, когда стоимость её масштабирования становится равной оценке стоимости перехода на новую архитектуру.
