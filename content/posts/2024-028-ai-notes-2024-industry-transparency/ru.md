---
title = "Заметки об ИИ в 2024: прозрачность индустрии"
tags = ["practice", "theory", "business"]
published_at = "2024-11-03T12:00:00+00:00"
seo_description = ""
seo_image = ""
---

<!-- TODO: description -->
<!-- TODO: tags -->
<!-- TODO: add image -->
<!-- TODO: add SEO image -->

Года полтора назад я опубликовал большой [прогноз об искусственном интеллекте]{post:silly-predictions-about-artificial-intelligence}. Почитайте, если ещё не читали — пока что он хорошо себя показывает.

Недавно решил его дополнить, но большой целостный пост всё никак не выходит, поэтому будет серия заметок.

Начну с прозрачности индустрии.

У текущей движухи с ИИ есть несколько крутых особенностей, которые облегчают её анализ.

**Малая задержка в получении информации об актуальном состоянии отрасли.**

Большая доля событий публична (сдесь и далее под «мы» буду иметь в виду абстрактную общественность):

- Мы либо в моменте знаем кто из ключевых компаний что делает, либо узнаём в течении полугода-года.
- Мы почти моментально узнаём, когда ключевые специалисты меняют компаниии, иногда, даже проекты.
- Мы в течении месяцев замечаем большую часть ~~важных~~ интересных научных подвижек. Например, после публикации препринта о [Kolmogorov-Arnold Networks](https://arxiv.org/abs/2404.19756) в течении нескольких месяцев тема прошла через этапы хайпа и первых проверок концепции на практике.

**Все крупные проекты ведутся опытными ИТ-бизнесменами.**

Эти люди умеют считать деньги и потенциальную выгоду от их распределения. Ладно, может не все прям умеют, но большинство скорее всего шарит лучше среднего.

Поэтому направления усилий компаний хорошо корреклируют с оценкой перспективности технологий. И с перспективностью поднятия хайпа тоже, справедливости ради.

Соответственно, если куда-то идут большие деньги, то довольно разумно предполагать один из двух вариантов, иногда сразу оба:

- Технология сочтена ~~достаточно перспективной~~ перспективнее большинсва других в плане потенциальной отдачи инвестиций. Отдачу, для себя, я интерпретирую как минимум 2-3 десятичных порядка.
- Запрос на какую-то фичу/возможность от потенцальных пользователей оценён настолько большим, что потенциальный профит оправдывает риск потери денег из-за неготовности технологий.

**Нехватка рук специализированных разработчиков/учёных vs обилие денег**

Если у вас есть лишний миллион долларов, то вы не сможете получить из воздуха нового специалиста по SOTA архитектурам нейронок быстрее, чем лет за пять, может за два-три, если человек особо способный. Можно только переманить уже готового специалиста, — перекинуть его с проекта на проект, если смотреть на проблему в масштабе человечества.

Для примера, есть версия, что [Google недавно купил стартап за 2.7 млрд$ только для того, чтобы забрать его основателей и core команду обратно к себе](https://www.linkedin.com/pulse/analyzing-googles-characterai-acquisition-sramana-mitra-iramc/).

Соответственно:

- Пространство возможных архитектур нейронок исследуется медленно — работа не масштабируется вливанием денег.
- Большинство денег вливается в масштабирование всего, что можно масштабировать: данных, железа, команд поддержки (сюда можно включить не только условных разметчиков данных, но и дорогих спецов из области MLOps или писателей кода под железо).

Это должно приводить к важным скрытым трендам, но это сугубо мои гипотезы:

- Выбор направлений иследований в коммерческих компаниях, а именно в них сейчас происходит большинство слледований, находится под сильным давлением необходимости масштабировать нейронки. Соответственно, более интересные (но хуже масштабируемые) подходы могут не получать должного внимания, что скажется в будущем на скорости прогресса.
- Даже после создания концепции перспективной архитектуры, её реальное внедрение будет отложено до момента, когда исчерапается весь запас масштабирования текущей актуальной архитектуры. Так как профит от масштабирования гарантированный и быстрый, а профит от перехода на новую архитектуру не гарантированный и не быстрый.
- Возрастает сложность доказательства «перспективности» архитектуры, так как актуальные архитектуры заоптимизированы до максимума и никакая новая разработка не покажет сопоставимых с ними результатов, даже если концептуально превосходит текущие решения. У её разработчиков просто не будет денег и времени на сопоставимые оптимизации.

Если доверять этим гипотезам, то можно очень чётко видеть реальный прогресс технологий нейронок.

Утрируя, когда условная OpenAI выпускает новую флагманскую модель, мы можем видеть:

- конкретные отличия в архитектуре от предыдущей модели;
- конкретные сроки на разработку/доведение до ума/оптимизацю нового решения из области архитектур.

То есть, качественне скачёк и время на него. Опираясь на них, в одной из будущих заметок я попробую оценить пределы прогресса.


------
Соответственно, мы можем видеть:

- Как перспективность того или иного пути развития видят сильные мира сего, игнориуя маркетинговый туман, который они же нагоняют.
- Как потенциал конкретной архитектуры/технологии достигает (пред)пика, когда стоимость её масштабирования становится равной оценке стоимости перехода на новую архитектуру.
