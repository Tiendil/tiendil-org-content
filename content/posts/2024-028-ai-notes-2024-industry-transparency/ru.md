---
title = "Прозрачность индустрии"
tags = ["practice", "theory", "neural-networks", "ai-notes-2024"]
series = "ai-notes-2024"
published_at = "2024-11-02T17:00:00+00:00"
seo_description = "Мои заметки об актуальном состоянии ИИ в конце 2024, эта часть о прозрачности индустрии."
seo_image = ""
---

Года полтора назад я опубликовал большой [прогноз об искусственном интеллекте]{post:silly-predictions-about-artificial-intelligence}. Почитайте, если ещё не читали — пока что он хорошо себя показывает.

Недавно решил его дополнить, но большой целостный пост всё никак не выходит, поэтому будет серия заметок.

/// brigid-series
tag = "ai-notes-2024"
///

Начну с прозрачности индустрии: у текущей движухи с ИИ есть несколько крутых особенностей, о которых я хочу поговорить.

<!-- more -->

## Малая задержка в получении информации об актуальном состоянии отрасли

Большая доля событий публична (сдесь и далее под «мы» буду иметь в виду абстрактную общественность):

- Мы либо в моменте знаем кто из ключевых компаний что делает, либо узнаём в течении полугода-года.
- Мы почти моментально узнаём, когда ключевые специалисты меняют компании, иногда, даже проекты.
- Мы в течении месяцев замечаем большую часть ~~важных~~ интересных научных подвижек. Например, после публикации препринта о [Kolmogorov-Arnold Networks](https://arxiv.org/abs/2404.19756) в течении нескольких месяцев тема прошла через этапы хайпа и первых проверок концепции на практике.

## Все крупные проекты ведутся опытными IT-бизнесменами

Эти люди умеют считать деньги и потенциальную выгоду от их распределения. Ладно, может не все прям умеют, но большинство скорее всего шарит лучше среднего.

Поэтому направления усилий компаний хорошо коррелируют с оценкой перспективности технологий. И с перспективностью поднятия хайпа тоже, справедливости ради.

Соответственно, если куда-то идут большие деньги, то довольно разумно предполагать один из двух вариантов, иногда сразу оба:

- Технология сочтена ~~достаточно перспективной~~ перспективнее большинства других в плане потенциальной отдачи инвестиций. Отдачу, для себя, я интерпретирую как минимум 2-3 десятичных порядка.
- Запрос на какую-то фичу/возможность от потенциальных пользователей оценён настолько большим, что потенциальный профит оправдывает риск потери денег из-за неготовности технологий.

## Нехватка рук специализированных разработчиков/учёных vs обилие денег

Если у вас есть лишний миллион долларов, то вы не сможете получить из воздуха нового специалиста по SOTA архитектурам нейронок быстрее, чем лет за пять, может за два-три, если человек особо способный. Можно только переманить уже готового специалиста, — перекинуть его с проекта на проект, если смотреть на проблему в масштабе человечества.

Для примера, есть версия, что [Google недавно купил стартап за 2.7 млрд$ только для того, чтобы забрать его основателей и core команду обратно к себе](https://www.linkedin.com/pulse/analyzing-googles-characterai-acquisition-sramana-mitra-iramc/).

Соответственно:

- Пространство возможных архитектур нейронок исследуется медленно — работа не масштабируется вливанием денег.
- Большинство денег вливается в масштабирование всего, что можно масштабировать: данных, железа, команд "поддержки". К последним можно отнести не только условных разметчиков данных, но и дорогих спецов: MLOps, системных программистов, разработчиков железа, etc.

Это должно приводить к важным скрытым трендам, но это сугубо мои гипотезы:

- Выбор направлений исследований в коммерческих компаниях, а именно в них сейчас происходит большинство исследований, находится под сильным давлением необходимости масштабировать нейронки. Соответственно, более интересные (но хуже масштабируемые) подходы могут не получать должного внимания, что скажется в будущем на скорости прогресса.
- Даже после создания концепции перспективной архитектуры, её реальное внедрение будет отложено до момента, когда исчерапается весь запас масштабирования текущей актуальной архитектуры. Так как профит от масштабирования гарантированный и быстрый, а профит от перехода на новую архитектуру не гарантированный и не быстрый.
- Возрастает сложность доказательства «перспективности» архитектуры, так как актуальные архитектуры заоптимизированы до максимума и никакая новая разработка не покажет сопоставимых с ними результатов, даже если концептуально превосходит текущие решения. У её разработчиков просто не будет денег и времени на сопоставимые оптимизации.

Если доверять этим гипотезам, то можно очень чётко видеть реальный прогресс технологий нейронок.

Утрируя, когда условная OpenAI выпускает новую флагманскую модель, мы можем видеть:

- конкретные отличия в архитектуре от предыдущей модели;
- конкретные сроки достижения пика возможностей (масштабирования) предыдущим SOTA решением.
- конкретные сроки на разработку/доведение до ума/оптимизацию нового архитектурного решения.

То есть, мы можем видеть серию качественных скачков и время между ними. Опираясь на эти данные, в одной из будущих заметок я попробую оценить пределы прогресса текущих технологий ИИ.
