---
title = "Прогноз"
tags = ["practice", "neural-networks", "ai-notes-2024", "futurology", "business", "economics"]
series = "ai-notes-2024"
published_at = "2024-11-23T17:00:00+00:00"
seo_description = ""
seo_image = ""
---

TODO: tags
TODO: published_at
TODO: description

Продолжаю заметки об ИИ на конец 2024 года.

/// brigid-series
tag = "ai-notes-2024"
///

В прошлых постах мы обсудили три тезиса:

- Анализируя решения крупных разработчиков ИИ, таких как OpenAI или Google, мы можем делать достаточно точные предположения о состоянии этой области знаний.
- Весь текущий прогресс стоит на одной конкретной базовой технологии — генеративных базах знаний, которые есть большие вероятностные модели.
- Развитие генеративных баз знаний выходит на плато, их дальнейшее развитие скорре будет поступательным/эволюционным, чем взрывным/революционным.

Опираясь на эти тезисы мы наконец можем поговорить о самой хайповой, самой животрипещущей теме: доколе будет лететь текущий прогресс? Ждёт ли нас сингулярность в 2025 году или всё останется как прежде? Когда же наконец появится наш бог из металла и ~~силикона~~ кремния?

Я уже публиковал большой и широкий [прогноз об искусственном интеллекте]{post:silly-predictions-about-artificial-intelligence}. Он всё ещё в силе — почитайте, я же не буду повторятся и сосредоточусь на нескольких самых ~~хайповых~~ интересных моментах.

<!-- more -->

## Технологической сингулярности не будет

В очередной раз сингулярность к нам не придёт.

Не будет такого, что в 2025 году появляется сильный ИИ, в 2026 решает проблему потепления, в 2027 лечит рак, в 2028 вводит всеобщий базовый доход, равноправие и бесплатные стейки из искуственного мяса, а в 2029 начинаются туристические поездки на Марс.

С сингулярностью важно помнить, что это не конректное явление, а абстрация для обозначения состояния мира в котором наши текущие модели реальности не работают.

Простым языком: никто не знает, что будет в таких-то граничных условиях, поэтому наши предсказания начинают загонять показатели в бесконечность. В математике/физике это происходит буквально, в случае реальной жизни — фигурально: всё будет максимально хорошо или всё будет максимально плохо.

Сложным языком:

- Мы мыслим сугубо в рамках моделей реальности в нашей голове;
- [Все модели имеют ограниченную область применения и ограниченную точность]{post:@choose-nearest-language:life-and-work-with-models}.
- Это значит, что всегда есть облати, в которых мы делаем плохие, неточные предсказания или вообще не можем их делать.
- Часто это области в которые мы попадаем в случае резкого изменения каких-либо параметров. Потому что наши модели обычно не расчитаны на это (редкая ситуация) и такие модели сложнее готовить.
- Ожидание технологической сингулярности — как раз такой случай. Одна или несколько технологий начинают настолько резко улучшаться, что последствия их развития выходят за границы определения наших моделей быстрее, чем мы эти модели адапитируем.

Отсюда у части людей случается ожидание рая на земле в предположении, что раз мы не знаем что конкретно порешают новые технологии, то они порешают всё. Ошибка простительная, но, к сожаению, многие пытаются эксплуатировать её в целях увелчинеия личного достатка или популярности.

Однако, когда резкое изменение реальность заканчивается, человечество собирает новые данные, пересматривает модели и начинает делать новые точные предсказания, до следующего рывка/резкого изменения, которое уж в этот-то раз точно приведёт к технологической сингулярности.

## От базовой технологии (нейронных сетей) ждать очередного прорыва не стоит

### Нейронные сети не отберут вашу работу

### Мы не получим сильный ИИ в виде одной или нескольких нейронных сетей

## Технологии над генеративными БД находятся в состоянии кота шрёдингера

### Архитектурная неизвестность

### Если архитектурный прорыв не случится

### Если архитектурный прорыв случится

#### Слабый ИИ: что он может изменить

#### Сильный ИИ: что он может изменить

## Конкретные прогнозы

- Придумают термин для того, что я называю Generative Knowledge Bases.
- Будут эксперементы в протоколах коммуникации агентов (текст, разные формы эмбедингов)
- Роботы и ограничения аккумуляторов
- Всё ещё расчитываю на развитие философской темы (см. http://0.0.0.0:8000/ru/posts/silly-predictions-about-artificial-intelligence)
- Генеративный ИИ как интеллектуальный разделитель: слабообразованные люди не будут видеть разницу между ИИ текстами и текстами профи. Профи будут видеть разницу и будут продолжать писать авторские тексты (с оформлением от ИИ)
- Конкуренция межу работом и человеком по дешевизне труда
