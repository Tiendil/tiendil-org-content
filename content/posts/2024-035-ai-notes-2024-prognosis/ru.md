---
title = "Прогноз"
tags = ["practice", "neural-networks", "society", "futurology", "ai-notes-2024", "economics", "interesting"]
series = "ai-notes-2024"
published_at = "2024-12-31T17:00:00+00:00"
seo_description = "Мои заметки об актуальном состоянии ИИ в конце 2024 года. В этом посте я делаю прогноз на ближайшие 5-10 лет."
seo_image = ""
---

Продолжаю заметки об ИИ на конец 2024 года.

/// brigid-series
tag = "ai-notes-2024"
///

В прошлых постах мы обсудили три тезиса:

- Анализируя решения крупных разработчиков ИИ, таких как OpenAI или Google, мы можем делать достаточно точные предположения о состоянии этой области знаний.
- Весь текущий прогресс стоит на одной конкретной базовой технологии — генеративных базах знаний, которые есть большие вероятностные модели.
- Развитие нейронных сетей, ака генеративных баз знаний, выходит на плато, их дальнейшее развитие скорее будет поступательным/эволюционным, чем взрывным/революционным.

Опираясь на эти тезисы мы наконец можем поговорить о самой хайповой, самой животрепещущей теме: доколе будет лететь текущий прогресс? Ждёт ли нас сингулярность в 2025 году или всё останется как прежде? Когда же наконец появится наш бог из металла и ~~силикона~~ кремния?

В 2023 я уже публиковал [прогноз об искусственном интеллекте]{post:silly-predictions-about-artificial-intelligence}. Он всё ещё в силе — почитайте. В том эссе я больше времени уделил тому, что следует ожидать. Новый текст вышел скорее про то, чего ожидать не следует. Получается, очертил две границы возможного, а истина где-то посередине будет.

<!-- more -->

## Технологической сингулярности не будет

В очередной раз сингулярность к нам не придёт.

Не будет такого, что в 2025 году появится сильный ИИ, в 2026 он решит проблему потепления, в 2027 вылечит рак, в 2028 введёт всеобщий базовый доход, насадит равноправие и раздаст бесплатные стейки из искусственного мяса, а в 2029 начнутся туристические полёты на Марс.

С сингулярностью важно помнить, что это не конкретное явление, а абстрация для обозначения состояния мира, в котором наши текущие модели реальности не работают.

Простым языком: никто не знает, что будет в определённых граничных условиях, поэтому наши предсказания загоняют показатели в бесконечность. В математике/физике это происходит буквально, в реальной жизни — фигурально: мы думаем, что всё будет максимально хорошо или максимально плохо.

Сложным языком:

- Мы мыслим сугубо в рамках моделей реальности в нашей голове.
- [Все модели имеют ограниченную область применения и ограниченную точность]{post:@choose-nearest-language:life-and-work-with-models}.
- Это значит, что всегда есть области, в которых мы делаем плохие, неточные предсказания или вообще не можем их делать.
- Часто это области, в которые мы попадаем в случае резкого изменения входных параметров модели. Потому что наши модели обычно не рассчитаны на это: редкая ситуация, сложнее готовить, etc.
- Ожидание технологической сингулярности — как раз такой случай. Одна или несколько технологий начинают настолько резко улучшаться, что последствия их развития выходят за границы определения наших моделей мира быстрее, чем мы эти модели адаптируем. Фактически, становится выгоднее подождать и посмотреть что будет, чем следовать неточным предсказаниям.

В подобных условиях у части людей случается ожидание рая на земле, в духе: раз мы не знаем что конкретно порешают новые технологии, то они порешают всё. Ошибка простительная, к сожалению, многие эксплуатируют её в целях увеличения личного достатка или популярности.

Однако резкие изменения всегда заканчиваются, человечество собирает новые данные, пересматривает модели и начинает делать новые точные предсказания. Все успокаиваются до следующего рывка/резкого изменения, которое уж в этот-то раз точно приведёт к технологической сингулярности.

## Нейронные сети концептуально не изменятся за 10 лет

Концептуально не изменятся — значит не обретут новых качественных свойств в дополнение к уже имеющимся. За подробностями приглашаю в пост про [генеративные базы данных]{post:ai-notes-2024-generative-knowledge-base}.

Под неконцептуальные изменения попадают увеличение скорости, качества, удешевление.

Я ограничиваю прогноз на ближайшие 10 лет, так как остаётся теоретическое пространство для качественного изменения нейронных сетей. Например, обучение текущих искусственных сетей отделено от рабочего режима, а биологические совмещают эти режимы как-минимум частично — добавление такой способности к искусственным сетям могло бы ещё раз перевернуть рынок.

Я считаю такие изменения маловероятными (в ближайшее время) по следующим причинам:

- Текущий прорыв в нейронных сетях на порядки расширил пространство возможных профитных продуктов для бизнеса.
- Бизнес — основной двигатель текущего прогресса.
- Исследовать пространство возможных профитных продуктов значительно выгоднее (по соотношению возможного профита к риску), чем искать ещё одно такое же пространство. Пока ты ищешь, конкуренты делят текущий рынок.
- На учёных тоже мало надежды, так как современная наука сломана и большинство учёных стремится за хайпом и деньгами.

Говоря образно, искусственные нейронные сети сейчас в состоянии рынка PC в конце 80-ых: интернет уже есть, все базовые концепции PC есть, базовые цепочки производства более-менее налажены или в процессе наладки. Да, за следующие 30 лет многое изменится, многое оптимизируется, развитие электроники спровоцирует множество меньших революций, но концептуально влияние PC на наш мир будет скорее количественно отмасштабированно, чем качественно. Утрируя, текстовые редакторы были уже в конце 80-ых, до нашего времени они концептуально не изменились, только стали красивее, удобнее, мощнее, etc.

## Мы не получим сильный ИИ только на базе одной или нескольких нейронных сетей

Не будем пытаться строго определить, что такое сильный ИИ — отдадим это философам, математикам и юристам. А то вот недавно [Microsoft и OpenAI дали определение сильному ИИ через количество заработанных денег](https://techcrunch.com/2024/12/26/microsoft-and-openai-have-a-financial-definition-of-agi-report/).

Мы люди простые, интуивно понимаем, что сильный ИИ — это примерно как человек. А слабый ИИ пусть будет примерно как дрессированная собачка или котик; или как модель, которая при невооружённом взгляде выглядит как сильный ИИ, но на самом деле не работает как он — этакий фантом сильного ИИ.

Про фантом сильного ИИ добавлю ещё пару слов.

При бесконечном количестве ресурсов можно собрать нечто, что будет вести себя как человек с точки зрения неподготовленного наблюдателя, абсолютно таким не являясь. Например, можно посадить толпу людей придумывать «человеческие» реакции на любое возможное событие, записать их в базу данных и выбирать реакции сугубо по табличке. Подобная система будет выглядеть как сильный ИИ до тех пор, пока не столкнётся с очень оригинальной ситуацией или пока ей не потребуется научиться (приспособиться к) чему-нибудь. Или можно обучить огромную статистическую модель, которая будет предсказывать текст, симулируя диалог с человеком, оставаясь статичной генеративной базой данных.

Очевидно, что при всей внешней похожести, такая система не будет являться сильным ИИ даже близко. Поэтому, например, я крайне скептически и неодобрительно отношусь к заявлениям (обычно бывших) сотрудников Google, OpenAI и прочих компаний, которые заявляют о якобы обнаруженном сознании в моделях.

Чтобы детально разобрать вопрос создания сильного ИИ, надо писать отдельный пост. Делать это, к сожалению, у меня нет времени, хотя и хочется. Поэтому ограничусь несколькими тезисами, которые подкрепляют мнение о малой вероятности создания сильного ИИ простым способом.

Тезис со стороны технологии.

Если смотреть на нейронные сети как на [генеративные базы данных]{post:ai-notes-2024-generative-knowledge-base}, то очевидно, что никакая база данных не может дать нам сильный ИИ, так как реализует только часть необходимой функциональности. Так же как реляционные базы данных и семантические сети не помогли нам создать сильный ИИ на базе экспертных систем в 80-ых и 90-ых годах.

Тезис со стороны образца целевой системы, который есть в нашем распоряжении.

Наш мозг точно не работает как одна универсальная или небольшое количество генерализированных сетей/компонентов. Мнения о том, сколько компонентов можно выделить в мозгу, расходятся, но их точно много (можно выделить [несколько десятков структур](https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D1%8B_%D0%BC%D0%BE%D0%B7%D0%B3%D0%B0)), либо очень много, либо просто огромное количество (если считать такие штуки как [кортикальные колонки](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BB%D0%BE%D0%BD%D0%BA%D0%B0_%D0%BA%D0%BE%D1%80%D1%82%D0%B5%D0%BA%D1%81%D0%B0)). Эти модули не только устроены по-разному, но и организованы в сложную архитектуру, требующую сложной инфраструктуры для коммуникации (говоря техническим языком).

Весь наш прогресс в сильном ИИ за последние лет 50 — это созданные несколько модулей, которые симулируют его кусочки, но как их собрать вместе, чем склеить, до сих пор никто не знает. Сейчас в наших руках появился ещё один базовый строительный блок, но для постройки строения из подобных блоков нам потребуется ещё много исследований и разработок. И дом этот окажется куда сложнее, чем гора кубиков.

## Нейронные сети сами по себе не отберут работу у большинства людей

Чуть подробнее на эту тему я писал в отдельном эссе [ИИ нас всех не(?) заменит]{post:ai-will-not-or-will-replace-us-all}

Поскольку сильный ИИ мы не ожидаем, то нейронные сети остаются (очень мощным) инструментом для интеллектуального труда. Возможно, самым мощным после письменности, но всё ещё инструментом. Такому инструменту всё ещё нужна направляющая рука, даже если эта рука будет направлять его очень абстрактно.

В реальности, насколько я помню, ещё ни одна революция автоматизации не уменьшала абсолютное количество рабочих мест — только перераспределяла их. Бизнес, в принципе, не заинтересован в сокращении производства, только в увеличении. Если что-то получается автоматизировать/оптимизировать/удешевить, то это повод больше масштабироваться, а масштабирование требует тех же работников, но переученных.

Новый рабочий инструмент сдвинет фокус профессий с более рутинных интеллектуальных задач, на менее рутинные. Это потребует от людей:

- Во-первых, более широкого и глубокого образования, так как увеличение абстракции ведёт к увеличению широты и глубины охватываемой ей области.
- Во-вторых, переучивания, так как инструмент новый, а всему новому надо учиться.
- В-третьих, базовой любознательности, чтобы вовремя заметить что пора учиться.

Люди не желающие учиться будут испытывать проблемы с работой. Но такие люди всегда испытывают проблемы с работой последние лет 100 — это не следствие внедрения новых инструментов.

Есть мнение, что прогресс в ИИ позволит людям выполнять работу, для которой у них раньше не хватало компетенций. Я это мнение не разделяю. Подобная ситуация возможна (и будет наблюдаться) как временное явление или отклонение от нормы, так как при наличии более интеллектуального инструмента его менее способных дублёр становится не нужен. Для примера, когда появились первые автомобили, законы некоторых стран требовали чтобы перед таким автомобилем шёл или бежал человек, чтобы предупреждать о движущемся транспорте. Понятное дело, подобная практика отмерла сама собой. То же самое произойдёт и с подобными «дублёрами» ИИ.

Реальные сложности могут возникнуть у нескольких категорий людей.

Во-первых, у людей с интеллектуальными ограничениями:

- Тривиальной работы будет становиться меньше.
- Будут перестраиваться рабочие иерархии и человек может оказаться в подчинении «робота» (который в подчинении человека), что будет непривычно, непонятно и неприятно.

Помощь таким людям с работой должна будет стать одним из фокусов государства. Однако я не считаю что появление ИИ как-то сдвинет планку «интеллектуальной нормальности», поэтому не могу назвать это массовой потерей работы.

Во-вторых, у малоимущих людей, которых тяжёлая работа загоняет в угол и не оставляет возможности учиться (например, работники складов некоторых корпораций, многие люди в странах третьего мира). Без возможности переучиваться люди будут терять работу без возможности быстро найти новую. **Помощь таким людям уже давно должна быть приоритетом любого здорового общества**, проблема существует очень давно, массовое внедрение ИИ её усугубит, но далеко не на порядок. Проработка такой помощи должна относиться скорее к долгосрочной стратегии государства, чем к специальным мерам по сглаживанию внедрения ИИ.

### Роботы не будут быстро и массово вытеснять ручной труд

Под роботами я имею в виду физических роботов, как гуманоидных, так и не очень.

Проблема с ними в том, что даже в случае идеальной ситуации с софтом (допустим сделали на 100% корректный), роботам ещё нужно железо (корпуса, шарниры, подшипники, гидравлика, etc) и электричество.

Для быстрого массового внедрения роботов производство сложного надёжного железа должно быть сопоставимо по объёму с производством автомобилей или даже быть больше него. Развёртывание такого производства требует не только времени, но и перераспределения ресурсов, адаптации производственных цепочек по всей планете. Утрируя, нельзя просто так начать добывать и перерабатывать на 5-15% больше полезных ископаемых (без ущерба для остальной промышленности).

С электричеством и аккумуляторами ещё сложнее.

Во-первых, на текущий момент роботы потребляют значительно больше энергии, чем люди. Существенного прогресса в сокращении потребления энергии техникой нет, поэтому заменять дешёвый физический труд роботами может оказаться не выгодно.

Во-вторых, давно есть вопросы по поводу достаточности ресурсов для производства аккумуляторов для автомобилей и носимой техники. Нет гарантии, что тех же редкоземельных элементов хватит ещё и на большое количество автономных роботов.

В-третьих, инфраструктура для производства электроэнергии на планете трещит по швам уже лет 10-15, электричества не хватает для всего. Датацентры, криптофермы не просто так строятся около крупных электростанций с дешёвой энергией — в других местах невыгодно. Массовая роботизация легко может увеличить запросы на электроэнергию x2 к бытовому сектору, чего точно достичь не получится без прорыва в производстве электричества, которого нет.

Поэтому поступательное движение в сторону роботизации, конечно,  будет, но массовое и быстрое внедрение роботов следует ждать скорее на сложных производствах, чем в сфере услуг, быту или на низкооплачиваемых работах в странах третьего мира.

### Местам проактивных профессионалов ничто не угрожает ближайшие лет 10

Под проактивными профессионалами я имею в виду любых людей, которые получили специальное образование, работают в своей области, аккумулируют опыт и знания в ней, расширяют кругозор и сферу ответственности.

Любой профи отметит, что в его области есть огромный невидимый пласт знаний и навыков, который отделяет новичка и профессионала. Обычно этот пласт сопоставим по размеру или превосходит пласт высшего образования. Причём отличие знаний и навыков профи в неформализированности. Они не записаны в учебниках, обычно они даже в словесной форме не выражены, а представляют собой образы в голове.

Конечно, профи может выразить их словами, но это потребует времени и усилий, а результат будет не на 100% аккуратным. Как блоггер и технический лид я за это ручаюсь — выдрать знания из головы и переложить куда-то так, чтобы читателям или коллегам было понятно — это сложно и долго. По сути, это отдельный навык и большой труд.

Соответственно, этих знаний и навыков сейчас нет в обучающих данных для нейронок. Частично нейронки учатся этому косвенно, но результат не лучший.

Нехватка знаний сказывается на способности нейронок создавать качественные ответы по глубоким профессиональным вопросам. Я с этим постоянно сталкиваюсь, например, часто видно что LLM не может сфокусироваться на нужных вещах в ответе и генерирует правильные, но совершенно ненужные штуки. Чтобы настроить фокус приходится писать огромные вводные со всем контекстом, а они не всегда помогают.

Схожая логика справедлива не только для профессиональных знаний, но и для знаний по активному проекту. Большинство таких знаний также находятся в головах людей в виде предубеждений, неявных соглашений, фантазий, намёков и прочего. Выразить их текстом в полном объёме мало кто сможет, так как мало кто умеет и мало у кого найдётся столько времени катать сочинение, которое устареет через месяц.

Поэтому в ближайшее время большая часть прогресса ИИ будет сосредоточена на решении очень конкретных очень ограниченных по области задач с расчётом на то, что выбор направления работы останется за профи. Матёрым профи потребуется переучиваться на новый инструмент, молодым специалистам придётся сходу получать больше продуктовых навыков, чем требовались на старте карьеры их предшественникам. И это хорошо.

Чтобы автоматизировать именно труд профи, необходимо решить несколько проблем:

1. Сделать систему, которая будет константно доучиваться на новых экспериментальных данных, в том числе на ошибочных данных, сознательно ошибочных, справедливых только для частного случая конкретного проекта. Пока существенных сдвигов в этом направлении не видно.
2. Сделать систему, которая полностью инвертирует поток управления/владения в проекте. Такая система должна будет владеть всей высокоуровневой информацией о проекте и делегировать конкретные задачи либо людям, либо ИИ агентам. Теоретически ничто не запрещает создать похожую систему, но работа это долгая и сложная, может потребовать чрезмерную формализацию неформализированных ныне взаимодействий.

Поэтому пока таких комбайнов я не жду.

## Неопределённость возможности сильного ИИ на текущих технологиях

Как я уже упоминал, сделать сильный ИИ чисто на текущих архитектурах нейронок не получится.

Но сделать сильный ИИ на текущих нейронках и какой-то архитектурной надстройки, в теории, возможно.

С одной стороны:

- Тот же RAG плюс несколько нейронок для обновления и базы знаний выглядит как потенциальный способ замкнуть цикл обратной связи (сбор информации, анализ, синтез, действие) и получить обучающиеся ИИ.
- Некоторые эксперименты с коммуникацией агентов в играх показывают, что относительно легко можно получить поведение, которое выглядит как осмысленное.

С другой стороны:

- У базовых экспериментов с коммуникацией агентов не появилось отмасштабированных продолжений, что наводит на мысль о скрытой сложности.
- Мы всё ещё не можем описать логическую архитектуру мозга, которая стоит за мышлением (физическую можем, но это как давать список молекул в торте для описания вкуса). Поэтому не знаем куда копать и не можем оценить сложность необходимой архитектурной надстройки (кроме того, что она будет сложной).
- Даже если предположить, что такая архитектурная надстройка может быть создана сейчас, нет оснований полагать, что она будет работать с разумной скоростью на разумных ресурсах. Возможно сильный ИИ потребует объединения миллиардов агентов, или ускорения коммуникации между ними в 1000 раз, или ещё чего-то, что сейчас не в нашей власти.

Утрируя, я готов допустить, что сейчас возможен проект уровня [Apollo](https://ru.wikipedia.org/wiki/%D0%90%D0%BF%D0%BE%D0%BB%D0%BB%D0%BE%D0%BD_(%D0%BA%D0%BE%D1%81%D0%BC%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0)) или [Manhattan](https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D0%BD%D1%85%D1%8D%D1%82%D1%82%D0%B5%D0%BD%D1%81%D0%BA%D0%B8%D0%B9_%D0%BF%D1%80%D0%BE%D0%B5%D0%BA%D1%82) по созданию сильного ИИ, но с большой вероятностью он не приведёт к внедрению такого ИИ в повседневную жизнь, как Apollo не привёл к колонизации Луны и даже к постоянному присутствию человека на ней.

Можно сказать, что сильный ИИ сейчас в состоянии кота Шрёдингера — когда ящик откроется, он либо заработает либо не заработает.

### Если архитектурный прорыв не случится

Ну не случится и не случится, будем жить как жили.

### Если архитектурный прорыв случится

Ну случится и случится, какая нам разница кто на другом конце провода при удалённой работе?

На самом деле, я считаю, что в случае появления сильного ИИ у человества прибавится проблем.

У нас уже хватает разного рода шовинистов, расистов, сексистов, *фобов, вечно обиженных и прочих личностей. С появлением сильного ИИ их станет ещё больше, появятся новые направления шовинизма, расизма, сексизма, фобий и прочего. Дурости прибавится и вот с ней как раз ИИ ничем не поможет — это проблемы наших институтов и нашей культуры, которые нам и расхлёбывать.

Фундаментальных проблем сильный ИИ добавит, а экономическая польза (по сравнению с развитым инструментарием на базе тех же нейронок) может быть не такой уж и большой.

### Если архитектурный прорыв случится и мы сделаем очень умный ИИ

Ну сделаем и сделаем :-)

Во-первых, человечество всегда находится в состоянии взаимодействия индивидуумов с разным интеллектом:

- Интеллект двух зрелых людей часто заметно отличается. Редко раза в 1.5, в особых случаях раза в 2.
- Зрелые люди как-то находят общий язык с детьми и пожилыми людьми, хотя разница знаний и мышления там может быть большой.
- Профессионалы (в какой-то области) находят общий язык с непрофессионалами (в той же области). Мы все, в конце концов, пользуемся услугами юристов и даже зубных врачей! Не говоря уже о психологах. Как-то всё это работает.

Поэтому, если ИИ вдруг станет слегка умнее человека, я не вижу проблем — адаптируемся.

В появление богоподобного сверх ИИ, логику которого мы не в состоянии постигнуть за разумное время, я не верю. Давайте сначала сделаем умных NPC в играх и научимся избирать умных депутатов, потом обсудим сверх ИИ, который будет решать судьбы человечества.

## Социальные риски

Я не вижу критических рисков в области экономики, экологии, ресурсов, производства — почти нигде, за исключением долгосрочных последствий для социальной сферы.

### Деградация экспертности

Новые инструменты позволяют реальным экспертам становиться ещё более осведомлёнными, принимать лучшие решения, работать эффективнее.

Но они не упрощают донесение новых сложных идей простым способом до остальных людей.

Зато эти же инструменты позволяют любому шарлатану выглядеть умно, экспертно. Переспорить условного антипрививочника, вооружённого современной языковой моделью, (перед неподготовленным судьёй) значительно сложнее, чем антипрививочника без неё.

Встречал мнение, что нейронки помогут любому желающему проверять информацию, рассчитывать на это я бы не стал:

- Во-первых, у человека должна быть привычка проверять информацию. У большинства её нет, вырабатывается она с трудом.
- Во-вторых, у человека должно появиться само желание проверять информацию. А зачем проверять, если она выглядит убедительно?
- В-третьих, LLM — это сложный инструмент. Как и любым сложным инструментом, им надо учиться пользоваться и не все смогут делать это эффективно.

Поэтому я жду больших волн разнообразной псевдонаучной и псевдорациональной дичи, вкупе с ухудшением уровня управления в демократических странах.

### Поляризация образованности

Использование ИИ человеком, подготовленным к работе с информацией сделает его ещё более информированным, образованным. Так как этот человек будет учиться использовать ИИ и будет учиться на результатах, выдаваемых ИИ.

Использование ИИ человеком неподготовленным создаст у этого человека иллюзию экспертности (себя). Такой человек не будет учиться, не будет критически смотреть на результаты своего взаимодействия с ИИ и на информацию, которая ему поступает. Среди программистов есть анекдоты про программирование через copy-paste со StackOverflow. Представьте ту же проблему, но в 100 раз хуже и во всех областях деятельности.

В итоге, люди с доступом к хорошему образованию и культуре, поощряющей самообучение, будут становиться успешнее. Люди без доступа к таким благам (которых большинство, к сожалению), будут становиться менее успешными.

## Итого

- Рай на земле не построим.
- Сильный ИИ не придёт и не спасёт нас от нас.
- Нейронные сети становятся важным рабочим инструментом, надо учиться с ними работать.
- ИИ будет сложно отобрать вашу работу, если вы следите за трендами, учитесь и работаете на совесть.
- Надо помогать людям, которым будет сложно переучиться.
- Надо учиться работать с информацией, тренировать критическое мышление.
- Надо тренировать продуктовое мышление.
