---
title = "Prognosis"
tags = ["practice", "neural-networks", "society", "futurology", "ai-notes-2024", "economics", "interesting"]
series = "ai-notes-2024"
published_at = "2024-12-31T17:00:00+00:00"
seo_description = "My notes on the current state of AI at the end of 2024. In this post, I make a forecast for the next 5-10 years."
seo_image = ""
---

I continue my notes on AI at the end of 2024.

/// brigid-series
tag = "ai-notes-2024"
///

In the previous posts we discussed three theses:

- By analyzing the decisions of major AI developers, such as OpenAI or Google, we can make fairly accurate assumptions about the state of the AI industry.
- All current progress is based on a single base technology — generative knowledge bases, which are large probabilistic models.
- The development of neural networks, a.k.a. generative knowledge bases, is reaching a plateau; their further advancement is likely to be incremental/evolutionary rather than explosive/revolutionary.

Based on these theses, we can finally talk about the most hyped, most exciting topic: how long will the current progress continue? Will we reach the singularity in 2025, or will everything remain the same? When will our god of metal and silicon finally appear?

In 2023, I already published a [forecast on artificial intelligence]{post:@choose-nearest-language:silly-predictions-about-artificial-intelligence}. It is still valid — take a look. In it, I spent more time describing what to expect. This text is more about what not to expect. So, it turns out that I outlined two boundaries of the possible, and the truth should be somewhere in between.

<!-- more -->

## There will be no technological singularity

Once again, the singularity will not come to us.

A strong AI ([AGI](https://en.wikipedia.org/wiki/Artificial_general_intelligence)) will not appear in 2025, solve the problem of global warming in 2026, cure cancer in 2027, introduce universal basic income in 2028, establish equality, and distribute free steaks made from artificial meat in 2029, and initiate tourist flights to Mars.

We should remember that the singularity is not a specific event or phenomenon, but an abstraction to denote a state of the world in which our current models of reality do not work.

In simple terms: nobody knows what will happen under certain boundary conditions, so our predictions push the numbers to infinity. In math or physics, this happens literally; in real life, it's more figurative — we assume everything will either turn out as perfectly as possible or as disastrously as possible.

In more complex terms:

- We think strictly within the boundaries of the models of reality in our heads.
- [All models have a limited range of application and limited accuracy]{post:@choose-nearest-language:life-and-work-with-models}.
- This means there are always areas where we make bad, inaccurate predictions, or can't make them at all.
- Often these are areas where we end up when the input parameters of the model change abruptly, too rapidly. Because our models are usually not designed for such cases: too rare situation, more difficult to prepare and tune, etc.
- The expectation of a technological singularity is precisely such a case. One or more technologies begin to improve so rapidly that the consequences of such improvements exceed the capabilities of our models faster than we can adapt them. As a result, it becomes more practical to wait and see what happens rather than rely on inaccurate predictions."

In such conditions, some people start to expect paradise on earth, reasoning that since we don’t know exactly what new technologies will solve, they’ll solve everything. This mistake is understandable, but unfortunately, many exploit it to boost their personal wealth or popularity.

However, rapid changes always come to an end. Humanity gathers new data, revises its models, and starts making accurate predictions again. Everyone calms down—until the next leap or sudden change, which, this time, is sure to lead to the technological singularity.

## Neural networks won't change conceptually over the next 10 years

By conceptual changes, I mean obtaining new qualitative properties in addition to the existing ones. For details, I invite you to read the post on [generative knowledge bases]{post:ai-notes-2024-generative-knowledge-base}.

By non-conceptual changes, I mean quantitative changes, like increasing speed, quality, or reducing costs.

I limit my forecast to the next 10 years because there is still theoretical room for a qualitative change in neural networks. For instance, current artificial networks separate training from their operational mode, whereas biological networks combine these modes at least partially. Adding such a capability to artificial networks could once again disrupt the market.

I believe such changes are unlikely (in the near future) for the following reasons:

- The current breakthrough in neural networks has expanded the space of potentially profitable products for businesses by orders of magnitude.
- Business is the main driver of current progress.
- Exploring the space of potentially profitable products is much more beneficial (in terms of the profit-to-risk ratio) than looking for another similar space. While you're looking, your competitors are dividing the current market.
- There is little hope for scientists either, as modern science is broken, and most researchers are driven by hype and money.

Speaking figuratively, artificial neural networks are currently at the stage of the PC market in the late 80s: the internet already exists, all the fundamental PC concepts are in place, and the basic production chains are either established or in the process of being established. Yes, many things will change over the next 30 years, many processes will be optimized, and the development of electronics will trigger numerous smaller revolutions. However, conceptually, the impact of PCs on our world will be more about quantitative scaling than qualitative transformation. To exaggerate, text editors already existed in the late 80s, and conceptually, they haven’t changed since — only becoming more polished, user-friendly, and powerful.

## Мы не получим сильный ИИ только на базе одной или нескольких нейронных сетей

Не будем пытаться строго определить, что такое сильный ИИ — отдадим это философам, математикам и юристам. А то вот недавно [Microsoft и OpenAI дали определение сильному ИИ через количество заработанных денег](https://techcrunch.com/2024/12/26/microsoft-and-openai-have-a-financial-definition-of-agi-report/).

Мы люди простые, интуивно понимаем, что сильный ИИ — это примерно как человек. А слабый ИИ пусть будет примерно как дрессированная собачка или котик; или как модель, которая при невооружённом взгляде выглядит как сильный ИИ, но на самом деле не работает как он — этакий фантом сильного ИИ.

Про фантом сильного ИИ добавлю ещё пару слов.

При бесконечном количестве ресурсов можно собрать нечто, что будет вести себя как человек с точки зрения неподготовленного наблюдателя, абсолютно таким не являясь. Например, можно посадить толпу людей придумывать «человеческие» реакции на любое возможное событие, записать их в базу данных и выбирать реакции сугубо по табличке. Подобная система будет выглядеть как сильный ИИ до тех пор, пока не столкнётся с очень оригинальной ситуацией или пока ей не потребуется научиться (приспособиться к) чему-нибудь. Или можно обучить огромную статистическую модель, которая будет предсказывать текст, симулируя диалог с человеком, оставаясь статичной генеративной базой данных.

Очевидно, что при всей внешней похожести, такая система не будет являться сильным ИИ даже близко. Поэтому, например, я крайне скептически и неодобрительно отношусь к заявлениям (обычно бывших) сотрудников Google, OpenAI и прочих компаний, которые заявляют о якобы обнаруженном сознании в моделях.

Чтобы детально разобрать вопрос создания сильного ИИ, надо писать отдельный пост. Делать это, к сожалению, у меня нет времени, хотя и хочется. Поэтому ограничусь несколькими тезисами, которые подкрепляют мнение о малой вероятности создания сильного ИИ простым способом.

Тезис со стороны технологии.

Если смотреть на нейронные сети как на [генеративные базы данных]{post:ai-notes-2024-generative-knowledge-base}, то очевидно, что никакая база данных не может дать нам сильный ИИ, так как реализует только часть необходимой функциональности. Так же как реляционные базы данных и семантические сети не помогли нам создать сильный ИИ на базе экспертных систем в 80-ых и 90-ых годах.

Тезис со стороны образца целевой системы, который есть в нашем распоряжении.

Наш мозг точно не работает как одна универсальная или небольшое количество генерализированных сетей/компонентов. Мнения о том, сколько компонентов можно выделить в мозгу, расходятся, но их точно много (можно выделить [несколько десятков структур](https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D1%8B_%D0%BC%D0%BE%D0%B7%D0%B3%D0%B0)), либо очень много, либо просто огромное количество (если считать такие штуки как [кортикальные колонки](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BB%D0%BE%D0%BD%D0%BA%D0%B0_%D0%BA%D0%BE%D1%80%D1%82%D0%B5%D0%BA%D1%81%D0%B0)). Эти модули не только устроены по-разному, но и организованы в сложную архитектуру, требующую сложной инфраструктуры для коммуникации (говоря техническим языком).

Весь наш прогресс в сильном ИИ за последние лет 50 — это созданные несколько модулей, которые симулируют его кусочки, но как их собрать вместе, чем склеить, до сих пор никто не знает. Сейчас в наших руках появился ещё один базовый строительный блок, но для постройки строения из подобных блоков нам потребуется ещё много исследований и разработок. И дом этот окажется куда сложнее, чем гора кубиков.

## Нейронные сети сами по себе не отберут работу у большинства людей

Чуть подробнее на эту тему я писал в отдельном эссе [ИИ нас всех не(?) заменит]{post:ai-will-not-or-will-replace-us-all}

Поскольку сильный ИИ мы не ожидаем, то нейронные сети остаются (очень мощным) инструментом для интеллектуального труда. Возможно, самым мощным после письменности, но всё ещё инструментом. Такому инструменту всё ещё нужна направляющая рука, даже если эта рука будет направлять его очень абстрактно.

В реальности, насколько я помню, ещё ни одна революция автоматизации не уменьшала абсолютное количество рабочих мест — только перераспределяла их. Бизнес, в принципе, не заинтересован в сокращении производства, только в увеличении. Если что-то получается автоматизировать/оптимизировать/удешевить, то это повод больше масштабироваться, а масштабирование требует тех же работников, но переученных.

Новый рабочий инструмент сдвинет фокус профессий с более рутинных интеллектуальных задач, на менее рутинные. Это потребует от людей:

- Во-первых, более широкого и глубокого образования, так как увеличение абстракции ведёт к увеличению широты и глубины охватываемой ей области.
- Во-вторых, переучивания, так как инструмент новый, а всему новому надо учиться.
- В-третьих, базовой любознательности, чтобы вовремя заметить что пора учиться.

Люди не желающие учиться будут испытывать проблемы с работой. Но такие люди всегда испытывают проблемы с работой последние лет 100 — это не следствие внедрения новых инструментов.

Есть мнение, что прогресс в ИИ позволит людям выполнять работу, для которой у них раньше не хватало компетенций. Я это мнение не разделяю. Подобная ситуация возможна (и будет наблюдаться) как временное явление или отклонение от нормы, так как при наличии более интеллектуального инструмента его менее способных дублёр становится не нужен. Для примера, когда появились первые автомобили, законы некоторых стран требовали чтобы перед таким автомобилем шёл или бежал человек, чтобы предупреждать о движущемся транспорте. Понятное дело, подобная практика отмерла сама собой. То же самое произойдёт и с подобными «дублёрами» ИИ.

Реальные сложности могут возникнуть у нескольких категорий людей.

Во-первых, у людей с интеллектуальными ограничениями:

- Тривиальной работы будет становиться меньше.
- Будут перестраиваться рабочие иерархии и человек может оказаться в подчинении «робота» (который в подчинении человека), что будет непривычно, непонятно и неприятно.

Помощь таким людям с работой должна будет стать одним из фокусов государства. Однако я не считаю что появление ИИ как-то сдвинет планку «интеллектуальной нормальности», поэтому не могу назвать это массовой потерей работы.

Во-вторых, у малоимущих людей, которых тяжёлая работа загоняет в угол и не оставляет возможности учиться (например, работники складов некоторых корпораций, многие люди в странах третьего мира). Без возможности переучиваться люди будут терять работу без возможности быстро найти новую. **Помощь таким людям уже давно должна быть приоритетом любого здорового общества**, проблема существует очень давно, массовое внедрение ИИ её усугубит, но далеко не на порядок. Проработка такой помощи должна относиться скорее к долгосрочной стратегии государства, чем к специальным мерам по сглаживанию внедрения ИИ.

### Роботы не будут быстро и массово вытеснять ручной труд

Под роботами я имею в виду физических роботов, как гуманоидных, так и не очень.

Проблема с ними в том, что даже в случае идеальной ситуации с софтом (допустим сделали на 100% корректный), роботам ещё нужно железо (корпуса, шарниры, подшипники, гидравлика, etc) и электричество.

Для быстрого массового внедрения роботов производство сложного надёжного железа должно быть сопоставимо по объёму с производством автомобилей или даже быть больше него. Развёртывание такого производства требует не только времени, но и перераспределения ресурсов, адаптации производственных цепочек по всей планете. Утрируя, нельзя просто так начать добывать и перерабатывать на 5-15% больше полезных ископаемых (без ущерба для остальной промышленности).

С электричеством и аккумуляторами ещё сложнее.

Во-первых, на текущий момент роботы потребляют значительно больше энергии, чем люди. Существенного прогресса в сокращении потребления энергии техникой нет, поэтому заменять дешёвый физический труд роботами может оказаться не выгодно.

Во-вторых, давно есть вопросы по поводу достаточности ресурсов для производства аккумуляторов для автомобилей и носимой техники. Нет гарантии, что тех же редкоземельных элементов хватит ещё и на большое количество автономных роботов.

В-третьих, инфраструктура для производства электроэнергии на планете трещит по швам уже лет 10-15, электричества не хватает для всего. Датацентры, криптофермы не просто так строятся около крупных электростанций с дешёвой энергией — в других местах невыгодно. Массовая роботизация легко может увеличить запросы на электроэнергию x2 к бытовому сектору, чего точно достичь не получится без прорыва в производстве электричества, которого нет.

Поэтому поступательное движение в сторону роботизации, конечно,  будет, но массовое и быстрое внедрение роботов следует ждать скорее на сложных производствах, чем в сфере услуг, быту или на низкооплачиваемых работах в странах третьего мира.

### Местам проактивных профессионалов ничто не угрожает ближайшие лет 10

Под проактивными профессионалами я имею в виду любых людей, которые получили специальное образование, работают в своей области, аккумулируют опыт и знания в ней, расширяют кругозор и сферу ответственности.

Любой профи отметит, что в его области есть огромный невидимый пласт знаний и навыков, который отделяет новичка и профессионала. Обычно этот пласт сопоставим по размеру или превосходит пласт высшего образования. Причём отличие знаний и навыков профи в неформализированности. Они не записаны в учебниках, обычно они даже в словесной форме не выражены, а представляют собой образы в голове.

Конечно, профи может выразить их словами, но это потребует времени и усилий, а результат будет не на 100% аккуратным. Как блоггер и технический лид я за это ручаюсь — выдрать знания из головы и переложить куда-то так, чтобы читателям или коллегам было понятно — это сложно и долго. По сути, это отдельный навык и большой труд.

Соответственно, этих знаний и навыков сейчас нет в обучающих данных для нейронок. Частично нейронки учатся этому косвенно, но результат не лучший.

Нехватка знаний сказывается на способности нейронок создавать качественные ответы по глубоким профессиональным вопросам. Я с этим постоянно сталкиваюсь, например, часто видно что LLM не может сфокусироваться на нужных вещах в ответе и генерирует правильные, но совершенно ненужные штуки. Чтобы настроить фокус приходится писать огромные вводные со всем контекстом, а они не всегда помогают.

Схожая логика справедлива не только для профессиональных знаний, но и для знаний по активному проекту. Большинство таких знаний также находятся в головах людей в виде предубеждений, неявных соглашений, фантазий, намёков и прочего. Выразить их текстом в полном объёме мало кто сможет, так как мало кто умеет и мало у кого найдётся столько времени катать сочинение, которое устареет через месяц.

Поэтому в ближайшее время большая часть прогресса ИИ будет сосредоточена на решении очень конкретных очень ограниченных по области задач с расчётом на то, что выбор направления работы останется за профи. Матёрым профи потребуется переучиваться на новый инструмент, молодым специалистам придётся сходу получать больше продуктовых навыков, чем требовались на старте карьеры их предшественникам. И это хорошо.

Чтобы автоматизировать именно труд профи, необходимо решить несколько проблем:

1. Сделать систему, которая будет константно доучиваться на новых экспериментальных данных, в том числе на ошибочных данных, сознательно ошибочных, справедливых только для частного случая конкретного проекта. Пока существенных сдвигов в этом направлении не видно.
2. Сделать систему, которая полностью инвертирует поток управления/владения в проекте. Такая система должна будет владеть всей высокоуровневой информацией о проекте и делегировать конкретные задачи либо людям, либо ИИ агентам. Теоретически ничто не запрещает создать похожую систему, но работа это долгая и сложная, может потребовать чрезмерную формализацию неформализированных ныне взаимодействий.

Поэтому пока таких комбайнов я не жду.

## Неопределённость возможности сильного ИИ на текущих технологиях

Как я уже упоминал, сделать сильный ИИ чисто на текущих архитектурах нейронок не получится.

Но сделать сильный ИИ на текущих нейронках и какой-то архитектурной надстройки, в теории, возможно.

С одной стороны:

- Тот же RAG плюс несколько нейронок для обновления и базы знаний выглядит как потенциальный способ замкнуть цикл обратной связи (сбор информации, анализ, синтез, действие) и получить обучающиеся ИИ.
- Некоторые эксперименты с коммуникацией агентов в играх показывают, что относительно легко можно получить поведение, которое выглядит как осмысленное.

С другой стороны:

- У базовых экспериментов с коммуникацией агентов не появилось отмасштабированных продолжений, что наводит на мысль о скрытой сложности.
- Мы всё ещё не можем описать логическую архитектуру мозга, которая стоит за мышлением (физическую можем, но это как давать список молекул в торте для описания вкуса). Поэтому не знаем куда копать и не можем оценить сложность необходимой архитектурной надстройки (кроме того, что она будет сложной).
- Даже если предположить, что такая архитектурная надстройка может быть создана сейчас, нет оснований полагать, что она будет работать с разумной скоростью на разумных ресурсах. Возможно сильный ИИ потребует объединения миллиардов агентов, или ускорения коммуникации между ними в 1000 раз, или ещё чего-то, что сейчас не в нашей власти.

Утрируя, я готов допустить, что сейчас возможен проект уровня [Apollo](https://ru.wikipedia.org/wiki/%D0%90%D0%BF%D0%BE%D0%BB%D0%BB%D0%BE%D0%BD_(%D0%BA%D0%BE%D1%81%D0%BC%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0)) или [Manhattan](https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D0%BD%D1%85%D1%8D%D1%82%D1%82%D0%B5%D0%BD%D1%81%D0%BA%D0%B8%D0%B9_%D0%BF%D1%80%D0%BE%D0%B5%D0%BA%D1%82) по созданию сильного ИИ, но с большой вероятностью он не приведёт к внедрению такого ИИ в повседневную жизнь, как Apollo не привёл к колонизации Луны и даже к постоянному присутствию человека на ней.

Можно сказать, что сильный ИИ сейчас в состоянии кота Шрёдингера — когда ящик откроется, он либо заработает либо не заработает.

### Если архитектурный прорыв не случится

Ну не случится и не случится, будем жить как жили.

### Если архитектурный прорыв случится

Ну случится и случится, какая нам разница кто на другом конце провода при удалённой работе?

На самом деле, я считаю, что в случае появления сильного ИИ у человества прибавится проблем.

У нас уже хватает разного рода шовинистов, расистов, сексистов, *фобов, вечно обиженных и прочих личностей. С появлением сильного ИИ их станет ещё больше, появятся новые направления шовинизма, расизма, сексизма, фобий и прочего. Дурости прибавится и вот с ней как раз ИИ ничем не поможет — это проблемы наших институтов и нашей культуры, которые нам и расхлёбывать.

Фундаментальных проблем сильный ИИ добавит, а экономическая польза (по сравнению с развитым инструментарием на базе тех же нейронок) может быть не такой уж и большой.

### Если архитектурный прорыв случится и мы сделаем очень умный ИИ

Ну сделаем и сделаем :-)

Во-первых, человечество всегда находится в состоянии взаимодействия индивидуумов с разным интеллектом:

- Интеллект двух зрелых людей часто заметно отличается. Редко раза в 1.5, в особых случаях раза в 2.
- Зрелые люди как-то находят общий язык с детьми и пожилыми людьми, хотя разница знаний и мышления там может быть большой.
- Профессионалы (в какой-то области) находят общий язык с непрофессионалами (в той же области). Мы все, в конце концов, пользуемся услугами юристов и даже зубных врачей! Не говоря уже о психологах. Как-то всё это работает.

Поэтому, если ИИ вдруг станет слегка умнее человека, я не вижу проблем — адаптируемся.

В появление богоподобного сверх ИИ, логику которого мы не в состоянии постигнуть за разумное время, я не верю. Давайте сначала сделаем умных NPC в играх и научимся избирать умных депутатов, потом обсудим сверх ИИ, который будет решать судьбы человечества.

## Социальные риски

Я не вижу критических рисков в области экономики, экологии, ресурсов, производства — почти нигде, за исключением долгосрочных последствий для социальной сферы.

### Деградация экспертности

Новые инструменты позволяют реальным экспертам становиться ещё более осведомлёнными, принимать лучшие решения, работать эффективнее.

Но они не упрощают донесение новых сложных идей простым способом до остальных людей.

Зато эти же инструменты позволяют любому шарлатану выглядеть умно, экспертно. Переспорить условного антипрививочника, вооружённого современной языковой моделью, (перед неподготовленным судьёй) значительно сложнее, чем антипрививочника без неё.

Встречал мнение, что нейронки помогут любому желающему проверять информацию, рассчитывать на это я бы не стал:

- Во-первых, у человека должна быть привычка проверять информацию. У большинства её нет, вырабатывается она с трудом.
- Во-вторых, у человека должно появиться само желание проверять информацию. А зачем проверять, если она выглядит убедительно?
- В-третьих, LLM — это сложный инструмент. Как и любым сложным инструментом, им надо учиться пользоваться и не все смогут делать это эффективно.

Поэтому я жду больших волн разнообразной псевдонаучной и псевдорациональной дичи, вкупе с ухудшением уровня управления в демократических странах.

### Поляризация образованности

Использование ИИ человеком, подготовленным к работе с информацией сделает его ещё более информированным, образованным. Так как этот человек будет учиться использовать ИИ и будет учиться на результатах, выдаваемых ИИ.

Использование ИИ человеком неподготовленным создаст у этого человека иллюзию экспертности (себя). Такой человек не будет учиться, не будет критически смотреть на результаты своего взаимодействия с ИИ и на информацию, которая ему поступает. Среди программистов есть анекдоты про программирование через copy-paste со StackOverflow. Представьте ту же проблему, но в 100 раз хуже и во всех областях деятельности.

В итоге, люди с доступом к хорошему образованию и культуре, поощряющей самообучение, будут становиться успешнее. Люди без доступа к таким благам (которых большинство, к сожалению), будут становиться менее успешными.

## Итого

- Рай на земле не построим.
- Сильный ИИ не придёт и не спасёт нас от нас.
- Нейронные сети становятся важным рабочим инструментом, надо учиться с ними работать.
- ИИ будет сложно отобрать вашу работу, если вы следите за трендами, учитесь и работаете на совесть.
- Надо помогать людям, которым будет сложно переучиться.
- Надо учиться работать с информацией, тренировать критическое мышление.
- Надо тренировать продуктовое мышление.
