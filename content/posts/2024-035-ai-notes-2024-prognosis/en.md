---
title = "Prognosis"
tags = ["practice", "neural-networks", "society", "futurology", "ai-notes-2024", "economics", "interesting"]
series = "ai-notes-2024"
published_at = "2024-12-31T17:00:00+00:00"
seo_description = "My notes on the current state of AI at the end of 2024. In this post, I make a forecast for the next 5-10 years."
seo_image = ""
---

I continue my notes on AI at the end of 2024.

/// brigid-series
tag = "ai-notes-2024"
///

In the previous posts we discussed three theses:

- By analyzing the decisions of major AI developers, such as OpenAI or Google, we can make fairly accurate assumptions about the state of the AI industry.
- All current progress is based on a single base technology — generative knowledge bases, which are large probabilistic models.
- The development of neural networks, a.k.a. generative knowledge bases, is reaching a plateau; their further advancement is likely to be incremental/evolutionary rather than explosive/revolutionary.

Based on these theses, we can finally talk about the most hyped, most exciting topic: how long will the current progress continue? Will we reach the singularity in 2025, or will everything remain the same? When will our god of metal and silicon finally appear?

In 2023, I already published a [forecast on artificial intelligence]{post:@choose-nearest-language:silly-predictions-about-artificial-intelligence}. It is still valid — take a look. In it, I spent more time describing what to expect. This text is more about what not to expect. So, it turns out that I outlined two boundaries of the possible, and the truth should be somewhere in between.

<!-- more -->

## There will be no technological singularity

Once again, the singularity will not come to us.

A strong AI ([AGI](https://en.wikipedia.org/wiki/Artificial_general_intelligence)) will not appear in 2025, solve the problem of global warming in 2026, cure cancer in 2027, introduce universal basic income in 2028, establish equality, and distribute free steaks made from artificial meat in 2029, and initiate tourist flights to Mars.

We should remember that the singularity is not a specific event or phenomenon, but an abstraction to denote a state of the world in which our current models of reality do not work.

In simple terms: nobody knows what will happen under certain boundary conditions, so our predictions push the numbers to infinity. In math or physics, this happens literally; in real life, it's more figurative — we assume everything will either turn out as perfectly as possible or as disastrously as possible.

In more complex terms:

- We think strictly within the boundaries of the models of reality in our heads.
- [All models have a limited range of application and limited accuracy]{post:@choose-nearest-language:life-and-work-with-models}.
- This means there are always areas where we make bad, inaccurate predictions, or can't make them at all.
- Often these are areas where we end up when the input parameters of the model change abruptly, too rapidly. Because our models are usually not designed for such cases: too rare situation, more difficult to prepare and tune, etc.
- The expectation of a technological singularity is precisely such a case. One or more technologies begin to improve so rapidly that the consequences of such improvements exceed the capabilities of our models faster than we can adapt them. As a result, it becomes more practical to wait and see what happens rather than rely on inaccurate predictions."

In such conditions, some people start to expect paradise on earth, reasoning that since we don’t know exactly what new technologies will solve, they’ll solve everything. This mistake is understandable, but unfortunately, many exploit it to boost their personal wealth or popularity.

However, rapid changes always come to an end. Humanity gathers new data, revises its models, and starts making accurate predictions again. Everyone calms down—until the next leap or sudden change, which, this time, is sure to lead to the technological singularity.

## Neural networks won't change conceptually over the next 10 years

By conceptual changes, I mean obtaining new qualitative properties in addition to the existing ones. For details, I invite you to read the post on [generative knowledge bases]{post:ai-notes-2024-generative-knowledge-base}.

By non-conceptual changes, I mean quantitative changes, like increasing speed, quality, or reducing costs.

I limit my forecast to the next 10 years because there is still theoretical room for a qualitative change in neural networks. For instance, current artificial networks separate training from their operational mode, whereas biological networks combine these modes at least partially. Adding such a capability to artificial networks could once again disrupt the market.

I believe such changes are unlikely (in the near future) for the following reasons:

- The current breakthrough in neural networks has expanded the space of potentially profitable products for businesses by orders of magnitude.
- Business is the main driver of current progress.
- Exploring the space of potentially profitable products is much more beneficial (in terms of the profit-to-risk ratio) than looking for another similar space. While you're looking, your competitors are dividing the current market.
- There is little hope for scientists either, as modern science is broken, and most researchers are driven by hype and money.

Speaking figuratively, artificial neural networks are currently at the stage of the PC market in the late 80s: the internet already exists, all the fundamental PC concepts are in place, and the basic production chains are either established or in the process of being established. Yes, many things will change over the next 30 years, many processes will be optimized, and the development of electronics will trigger numerous smaller revolutions. However, conceptually, the impact of PCs on our world will be more about quantitative scaling than qualitative transformation. To exaggerate, text editors already existed in the late 80s, and conceptually, they haven’t changed since — only becoming more polished, user-friendly, and powerful.

## We won't build strong AI based on just one or a few neural networks

Let's not try to strictly define what strong AI is — let's leave that to philosophers, mathematicians, and lawyers. After all, not long ago, [Microsoft and OpenAI defined strong AI in terms of the amount of money it generates](https://techcrunch.com/2024/12/26/microsoft-and-openai-have-a-financial-definition-of-agi-report/).

We are simple folks and intuitively understand strong AI as something roughly similar to a human. Weak AI, on the other hand, might resemble a trained dog or cat, or a model that, at first glance, appears to be strong AI but doesn’t function like it—a sort of strong AI phantom.

Let's me add a few words about the phantom of strong AI.

With infinite resources, we could create something that behaves like a human to an unprepared observer but is not human at all. For instance, we could gather a crowd of people to list "human" reactions to all possible events, record them in a database, and select reactions based on a lookup table. Such a system would behave (from third party view) like strong AI until it encounters an original situation or needs to learn (adapt to) something new. Or we could train a huge statistical model to predict text token-by-token, simulating a dialogue with a human, while remaining a static generative knowledge base.

Obviously, while such a system might look like strong AI, it won't be strong AI by any means. This is why I'm extremely skeptical and dissapointed by claims — usually made by former employees of Google, OpenAI, and other companies — that consciousness has been discovered in modern models.

The question of creating strong AI is a complex one and requires a separate post to delve into. Unfortunately, I don't have time to write it, although I would like to. So I'll limit myself to a few theses supporting the idea that creating strong AI through simple means is highly unlikely.

The thesis from the perspective of technology.

If we view neural networks as [generative knowledge bases]{post:ai-notes-2024-generative-knowledge-base}, it becomes clear that no database can give us strong AI, as it implements only part of the necessary functionality (stores information). Similarly, relational databases and semantic networks did not lead us to a strong AI based on expert systems in the 80s and 90s..

The thesis from the perspective of the target system, wich we have at our disposal.

Our brain clearly doesn’t function as a single universal network or just a few generalized networks/components. Opinions differ on how many components can be identified in the brain, but there are undoubtedly many of them ([several dozen structures](https://en.wikipedia.org/wiki/List_of_regions_in_the_human_brain) can be identified), or even more, or simply an enormous number (if we consider things like [cortical columns](https://en.wikipedia.org/wiki/Cortical_column) as a separate modules). These modules are not only structured differently but are also organized into a complex architecture requiring a sophisticated communication infrastructure (in technical terms).

Our entire progress in strong AI over the past 50 years has been about creating a few modules that simulate its fragments or abstract functions. However, no one yet knows how to assemble them or what to use to glue them together. Recently, we've gained another building block in our hands, but constructing a structure from such blocks will require much more research and development. And this structure will be far more complex than just a pile of uniform cubes.

## Neural networks on their own won’t take jobs away

I wrote a bit more on this topic in a separate essay: [AI will not(?) replace us all](post:@choose-nearest-language:ai-will-not-or-will-replace-us-all).

Since we don't expect strong AI, neural networks remain a (very powerful) tool for automation intellectual work. Perhaps the most powerful tool after writing, but still a tool. Such a tool still needs a guiding hand, even if it guides it very abstractly.

In reality, as far as I remember, no automation revolution has ever reduced the absolute number of jobs — only redistributed them. Business, in principle, is not interested in reducing production, only in increasing it: if something can be automated/optimized/made cheaper, it's a reason to scale up, and scaling up requires the (retrained) workers.

The new tool will shift the focus of professions from more routine intellectual tasks to less routine ones. This will require people to:

- acquire a broader and deeper education, as increased abstraction means a broader and deeper area of responsibility;
- retrain, as the tool is new and anything new requires learning;
- cultivate basic curiosity to recognize when it’s time to start learning.

People, who don't want to learn, will encounter problems with work. But such people have always had problems in this area for the past 100 years — it's not a consequence of one more tool being introduced.

There’s a view that progress in AI will enable people to perform work for which they previously lacked the necessary competencies. I don't share this opinion. Such a situation may arise (and will be observed) as a temporary phenomenon or a deviation from the norm, since the presence of a more intelligent tool (like a neural network) makes its less capable counterpart (an incompetent user) unnecessary.

For example, when the first cars appeared, the laws of some countries required a person to walk or run in front of the vehicle to warn others of approaching transport. Of course, this practice faded away on its own. The same will happen with such "AI counterparts."

In reality, the real difficulties will arise for several categories of people.

First of all, for people with intellectual disabilities:

- There may be less trivial work available.
- Work hierarchies may be restructured, and a person might find themselves subordinate to a "robot" (which, in turn, is subordinate to another person), a situation that could feel unusual, confusing, and unpleasant.

Helping such people find work should become one of the state’s priorities. However, I don’t believe that the advent of AI will shift the bar for "intellectual normality", so I wouldn’t consider this a case of mass job loss.

Secondly, for low-income individuals whose demanding jobs leave them cornered with no time or opportunity to learn (e.g., warehouse workers at certain corporations, many people in developing countries). Without the chance to retrain, they risk losing jobs without being able to quickly find new ones. **Helping such people should have long been a priority for any healthy society**. This issue has existed for a long time, and the adoption of AI will exacerbate it, though not dramatically. Addressing this problem should be part of the state’s long-term strategy rather than limited to specific measures aimed at easing AI integration.

### Robots will not rapidly and massively replace manual labor

By robots, I mean physical robots, both humanoid and non-humanoid.

The question with robots is that even in the case of perfect software (let's say it's working on 100%), robots still need hardware (bodies, joints, bearings, hydraulics, etc.) and electricity.

For the rapid and widespread adoption of robots, the production of complex, reliable hardware would need to match or even surpass the scale of automobile manufacturing. Scaling up such production requires not only time but also a redistribution of resources and adaptation of production chains across the globe. To put it bluntly, you can’t simply start extracting and processing 5-15% more raw materials without impacting the rest of the industry.

It's even more complicated with electricity and batteries.

Firstly, current models of robots consume significantly more energy than humans. There has been no significant progress in reducing energy consumption, so replacing cheap physical labor with robots may not be profitable in some cases.

Secondly, there have long been concerns about the sufficiency of resources for producing batteries for cars and wearable devices. There’s no guarantee that the same rare earth elements will be enough to support the production of a large number of autonomous robots.

Thirdly, the planet's energy production infrastructure has been under strain for the past 10-15 years, and there’s already not enough electricity to meet all demands. Data centers and crypto farms are built near large power plants with cheap energy for a reason — they are not economically viable elsewhere. Mass robotization could easily double the energy demands of the residential sector, which would be impossible to meet without a breakthrough in energy production — something that hasn’t happened yet.

Therefore, while there will be a gradual move towards robotization, it will be more likely to occur in complex manufacturing environments than in the service sector, households, or low-paid jobs in developing countries.

### Местам проактивных профессионалов ничто не угрожает ближайшие лет 10

Под проактивными профессионалами я имею в виду любых людей, которые получили специальное образование, работают в своей области, аккумулируют опыт и знания в ней, расширяют кругозор и сферу ответственности.

Любой профи отметит, что в его области есть огромный невидимый пласт знаний и навыков, который отделяет новичка и профессионала. Обычно этот пласт сопоставим по размеру или превосходит пласт высшего образования. Причём отличие знаний и навыков профи в неформализированности. Они не записаны в учебниках, обычно они даже в словесной форме не выражены, а представляют собой образы в голове.

Конечно, профи может выразить их словами, но это потребует времени и усилий, а результат будет не на 100% аккуратным. Как блоггер и технический лид я за это ручаюсь — выдрать знания из головы и переложить куда-то так, чтобы читателям или коллегам было понятно — это сложно и долго. По сути, это отдельный навык и большой труд.

Соответственно, этих знаний и навыков сейчас нет в обучающих данных для нейронок. Частично нейронки учатся этому косвенно, но результат не лучший.

Нехватка знаний сказывается на способности нейронок создавать качественные ответы по глубоким профессиональным вопросам. Я с этим постоянно сталкиваюсь, например, часто видно что LLM не может сфокусироваться на нужных вещах в ответе и генерирует правильные, но совершенно ненужные штуки. Чтобы настроить фокус приходится писать огромные вводные со всем контекстом, а они не всегда помогают.

Схожая логика справедлива не только для профессиональных знаний, но и для знаний по активному проекту. Большинство таких знаний также находятся в головах людей в виде предубеждений, неявных соглашений, фантазий, намёков и прочего. Выразить их текстом в полном объёме мало кто сможет, так как мало кто умеет и мало у кого найдётся столько времени катать сочинение, которое устареет через месяц.

Поэтому в ближайшее время большая часть прогресса ИИ будет сосредоточена на решении очень конкретных очень ограниченных по области задач с расчётом на то, что выбор направления работы останется за профи. Матёрым профи потребуется переучиваться на новый инструмент, молодым специалистам придётся сходу получать больше продуктовых навыков, чем требовались на старте карьеры их предшественникам. И это хорошо.

Чтобы автоматизировать именно труд профи, необходимо решить несколько проблем:

1. Сделать систему, которая будет константно доучиваться на новых экспериментальных данных, в том числе на ошибочных данных, сознательно ошибочных, справедливых только для частного случая конкретного проекта. Пока существенных сдвигов в этом направлении не видно.
2. Сделать систему, которая полностью инвертирует поток управления/владения в проекте. Такая система должна будет владеть всей высокоуровневой информацией о проекте и делегировать конкретные задачи либо людям, либо ИИ агентам. Теоретически ничто не запрещает создать похожую систему, но работа это долгая и сложная, может потребовать чрезмерную формализацию неформализированных ныне взаимодействий.

Поэтому пока таких комбайнов я не жду.

## Неопределённость возможности сильного ИИ на текущих технологиях

Как я уже упоминал, сделать сильный ИИ чисто на текущих архитектурах нейронок не получится.

Но сделать сильный ИИ на текущих нейронках и какой-то архитектурной надстройки, в теории, возможно.

С одной стороны:

- Тот же RAG плюс несколько нейронок для обновления и базы знаний выглядит как потенциальный способ замкнуть цикл обратной связи (сбор информации, анализ, синтез, действие) и получить обучающиеся ИИ.
- Некоторые эксперименты с коммуникацией агентов в играх показывают, что относительно легко можно получить поведение, которое выглядит как осмысленное.

С другой стороны:

- У базовых экспериментов с коммуникацией агентов не появилось отмасштабированных продолжений, что наводит на мысль о скрытой сложности.
- Мы всё ещё не можем описать логическую архитектуру мозга, которая стоит за мышлением (физическую можем, но это как давать список молекул в торте для описания вкуса). Поэтому не знаем куда копать и не можем оценить сложность необходимой архитектурной надстройки (кроме того, что она будет сложной).
- Даже если предположить, что такая архитектурная надстройка может быть создана сейчас, нет оснований полагать, что она будет работать с разумной скоростью на разумных ресурсах. Возможно сильный ИИ потребует объединения миллиардов агентов, или ускорения коммуникации между ними в 1000 раз, или ещё чего-то, что сейчас не в нашей власти.

Утрируя, я готов допустить, что сейчас возможен проект уровня [Apollo](https://ru.wikipedia.org/wiki/%D0%90%D0%BF%D0%BE%D0%BB%D0%BB%D0%BE%D0%BD_(%D0%BA%D0%BE%D1%81%D0%BC%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0)) или [Manhattan](https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D0%BD%D1%85%D1%8D%D1%82%D1%82%D0%B5%D0%BD%D1%81%D0%BA%D0%B8%D0%B9_%D0%BF%D1%80%D0%BE%D0%B5%D0%BA%D1%82) по созданию сильного ИИ, но с большой вероятностью он не приведёт к внедрению такого ИИ в повседневную жизнь, как Apollo не привёл к колонизации Луны и даже к постоянному присутствию человека на ней.

Можно сказать, что сильный ИИ сейчас в состоянии кота Шрёдингера — когда ящик откроется, он либо заработает либо не заработает.

### Если архитектурный прорыв не случится

Ну не случится и не случится, будем жить как жили.

### Если архитектурный прорыв случится

Ну случится и случится, какая нам разница кто на другом конце провода при удалённой работе?

На самом деле, я считаю, что в случае появления сильного ИИ у человества прибавится проблем.

У нас уже хватает разного рода шовинистов, расистов, сексистов, *фобов, вечно обиженных и прочих личностей. С появлением сильного ИИ их станет ещё больше, появятся новые направления шовинизма, расизма, сексизма, фобий и прочего. Дурости прибавится и вот с ней как раз ИИ ничем не поможет — это проблемы наших институтов и нашей культуры, которые нам и расхлёбывать.

Фундаментальных проблем сильный ИИ добавит, а экономическая польза (по сравнению с развитым инструментарием на базе тех же нейронок) может быть не такой уж и большой.

### Если архитектурный прорыв случится и мы сделаем очень умный ИИ

Ну сделаем и сделаем :-)

Во-первых, человечество всегда находится в состоянии взаимодействия индивидуумов с разным интеллектом:

- Интеллект двух зрелых людей часто заметно отличается. Редко раза в 1.5, в особых случаях раза в 2.
- Зрелые люди как-то находят общий язык с детьми и пожилыми людьми, хотя разница знаний и мышления там может быть большой.
- Профессионалы (в какой-то области) находят общий язык с непрофессионалами (в той же области). Мы все, в конце концов, пользуемся услугами юристов и даже зубных врачей! Не говоря уже о психологах. Как-то всё это работает.

Поэтому, если ИИ вдруг станет слегка умнее человека, я не вижу проблем — адаптируемся.

В появление богоподобного сверх ИИ, логику которого мы не в состоянии постигнуть за разумное время, я не верю. Давайте сначала сделаем умных NPC в играх и научимся избирать умных депутатов, потом обсудим сверх ИИ, который будет решать судьбы человечества.

## Социальные риски

Я не вижу критических рисков в области экономики, экологии, ресурсов, производства — почти нигде, за исключением долгосрочных последствий для социальной сферы.

### Деградация экспертности

Новые инструменты позволяют реальным экспертам становиться ещё более осведомлёнными, принимать лучшие решения, работать эффективнее.

Но они не упрощают донесение новых сложных идей простым способом до остальных людей.

Зато эти же инструменты позволяют любому шарлатану выглядеть умно, экспертно. Переспорить условного антипрививочника, вооружённого современной языковой моделью, (перед неподготовленным судьёй) значительно сложнее, чем антипрививочника без неё.

Встречал мнение, что нейронки помогут любому желающему проверять информацию, рассчитывать на это я бы не стал:

- Во-первых, у человека должна быть привычка проверять информацию. У большинства её нет, вырабатывается она с трудом.
- Во-вторых, у человека должно появиться само желание проверять информацию. А зачем проверять, если она выглядит убедительно?
- В-третьих, LLM — это сложный инструмент. Как и любым сложным инструментом, им надо учиться пользоваться и не все смогут делать это эффективно.

Поэтому я жду больших волн разнообразной псевдонаучной и псевдорациональной дичи, вкупе с ухудшением уровня управления в демократических странах.

### Поляризация образованности

Использование ИИ человеком, подготовленным к работе с информацией сделает его ещё более информированным, образованным. Так как этот человек будет учиться использовать ИИ и будет учиться на результатах, выдаваемых ИИ.

Использование ИИ человеком неподготовленным создаст у этого человека иллюзию экспертности (себя). Такой человек не будет учиться, не будет критически смотреть на результаты своего взаимодействия с ИИ и на информацию, которая ему поступает. Среди программистов есть анекдоты про программирование через copy-paste со StackOverflow. Представьте ту же проблему, но в 100 раз хуже и во всех областях деятельности.

В итоге, люди с доступом к хорошему образованию и культуре, поощряющей самообучение, будут становиться успешнее. Люди без доступа к таким благам (которых большинство, к сожалению), будут становиться менее успешными.

## Итого

- Рай на земле не построим.
- Сильный ИИ не придёт и не спасёт нас от нас.
- Нейронные сети становятся важным рабочим инструментом, надо учиться с ними работать.
- ИИ будет сложно отобрать вашу работу, если вы следите за трендами, учитесь и работаете на совесть.
- Надо помогать людям, которым будет сложно переучиться.
- Надо учиться работать с информацией, тренировать критическое мышление.
- Надо тренировать продуктовое мышление.
